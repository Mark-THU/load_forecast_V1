{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB-FNN预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T03:10:25.032084Z",
     "start_time": "2021-12-19T03:10:23.904156Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54067,
     "status": "ok",
     "timestamp": 1635322610395,
     "user": {
      "displayName": "Mark Dong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04537685704836554558"
     },
     "user_tz": -480
    },
    "id": "k73zvW4ktS3o",
    "outputId": "b475ea3d-f3d7-4694-81ec-35e5e1814612"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sqlalchemy import create_engine\n",
    "from xgboost import XGBRegressor\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T03:10:51.140537Z",
     "start_time": "2021-12-19T03:10:51.043364Z"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1635322610899,
     "user": {
      "displayName": "Mark Dong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04537685704836554558"
     },
     "user_tz": -480
    },
    "id": "exclb4QytS3v"
   },
   "outputs": [],
   "source": [
    "url = '../dataset_0101110000.csv'\n",
    "data = pd.read_csv(url, sep=',', index_col='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T03:11:32.875087Z",
     "start_time": "2021-12-19T03:11:32.869112Z"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1635322610900,
     "user": {
      "displayName": "Mark Dong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04537685704836554558"
     },
     "user_tz": -480
    },
    "id": "H6ag8TcBtS3w"
   },
   "outputs": [],
   "source": [
    "# 归一化\n",
    "def normalization(data):\n",
    "    \"\"\"\n",
    "    data: original data with load\n",
    "    return: normalized data, scaler of load\n",
    "    \"\"\"\n",
    "    normalized_data = MinMaxScaler().fit_transform(data)\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_y.fit_transform(data[['load']])\n",
    "    return normalized_data, scaler_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建监督学习数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T03:12:22.988721Z",
     "start_time": "2021-12-19T03:12:22.975139Z"
    },
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1635326461751,
     "user": {
      "displayName": "Mark Dong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04537685704836554558"
     },
     "user_tz": -480
    },
    "id": "HMBeK7TutS3x"
   },
   "outputs": [],
   "source": [
    "# build supervised data\n",
    "def Series_To_Supervise(data, seq_len, y_col_index):\n",
    "    \"\"\"\n",
    "    convert series data to supervised data\n",
    "    :param data: original data\n",
    "    :param seq_len: length of sequence\n",
    "    :y_col_index: index of column which acts as output\n",
    "    :return: return two ndarrays-- input and output in format suitable to feed to LSTM\n",
    "    \"\"\"\n",
    "    dim_0 = data.shape[0] - seq_len -24\n",
    "    dim_1 = data.shape[1]\n",
    "    x = np.zeros((dim_0, seq_len, dim_1))\n",
    "    y = np.zeros((dim_0, 24))\n",
    "    for i in range(0, dim_0):\n",
    "        x[i] = data[i: i+seq_len]\n",
    "        y[i] = data[i+seq_len:i+seq_len+24, y_col_index]\n",
    "    print(\"Supervised Train Data: Shape of x: {}, Shape of y: {}\".format(x.shape, y.shape))\n",
    "    return x, y\n",
    "\n",
    "def Series_To_Supervise_Test(data, seq_len, y_col_index):\n",
    "    \"\"\"\n",
    "    convert series data to supervised data\n",
    "    :param data: original data\n",
    "    :param seq_len: length of sequence\n",
    "    :y_col_index: index of column which acts as output\n",
    "    :return: return two ndarrays-- input and output in format suitable to feed to LSTM\n",
    "    \"\"\"\n",
    "    dim_0 = int((data.shape[0] - seq_len -24)/24)+1\n",
    "    dim_1 = data.shape[1]\n",
    "    x = np.zeros((dim_0, seq_len, dim_1))\n",
    "    y = np.zeros((dim_0, 24))\n",
    "    for i in range(0, dim_0):\n",
    "        x[i] = data[i*24: i*24+seq_len]\n",
    "        y[i] = data[i*24+seq_len:i*24+seq_len+24, y_col_index]\n",
    "    print(\"Supervised Test Data: Shape of x: {}, Shape of y: {}\".format(x.shape, y.shape))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T03:12:41.627943Z",
     "start_time": "2021-12-19T03:12:41.619930Z"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1635322610901,
     "user": {
      "displayName": "Mark Dong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04537685704836554558"
     },
     "user_tz": -480
    },
    "id": "GZm1OQW3tS3x"
   },
   "outputs": [],
   "source": [
    "# 5-fold cross-validation\n",
    "def split_dataset(X, Y, n_split=5):\n",
    "    \"\"\"\n",
    "    X: original feature, size * 72 * features\n",
    "    Y: labels, size * 1\n",
    "    return: list of train_x, test_x, train_y, test_y\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_split, shuffle=True, random_state=1)\n",
    "    train_x_list = list()\n",
    "    valid_x_list = list()\n",
    "    train_y_list = list()\n",
    "    valid_y_list = list()\n",
    "    for train_index, valid_index in kf.split(X):\n",
    "        train_x_list.append(X[train_index])\n",
    "        train_y_list.append(Y[train_index])\n",
    "        valid_x_list.append(X[valid_index])\n",
    "        valid_y_list.append(Y[valid_index])\n",
    "    return train_x_list, valid_x_list, train_y_list, valid_y_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义FNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T03:12:57.460034Z",
     "start_time": "2021-12-19T03:12:57.451691Z"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1635322610902,
     "user": {
      "displayName": "Mark Dong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04537685704836554558"
     },
     "user_tz": -480
    },
    "id": "sqWX9_T8tS3y"
   },
   "outputs": [],
   "source": [
    "# define FNN model \n",
    "class FNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A fnn neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_dim):\n",
    "        super(FNN, self).__init__()\n",
    "        \n",
    "        self.fnn = nn.Sequential(\n",
    "            nn.Linear(input_size, 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 24),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fnn(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1635327357833,
     "user": {
      "displayName": "Mark Dong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04537685704836554558"
     },
     "user_tz": -480
    },
    "id": "hzfsNsTHtS3y"
   },
   "outputs": [],
   "source": [
    "# train the model \n",
    "def Train_Model(train_x_list, train_y_list, valid_x_list, valid_y_list, batch_size, lr, number_epoch, input_size, hidden_dim, seq_len):\n",
    "    model_fnn = FNN(input_size, hidden_dim)\n",
    "    model_fnn.to(device=device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model_fnn.parameters(), lr=lr)\n",
    "    valid_loss_min = np.Inf\n",
    "    for i in range(5):\n",
    "      print('train dataset {}'.format(i))\n",
    "      train_x = train_x_list[i]\n",
    "      train_y = train_y_list[i]\n",
    "      valid_x = valid_x_list[i]\n",
    "      valid_y = valid_y_list[i]\n",
    "      train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "      valid_x = valid_x.reshape(valid_x.shape[0], -1)\n",
    "      train_dataset = TensorDataset(torch.FloatTensor(train_x), torch.FloatTensor(train_y))\n",
    "      valid_dataset = TensorDataset(torch.FloatTensor(valid_x), torch.FloatTensor(valid_y))\n",
    "      train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "      valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "      num_without_imp = 0\n",
    "      for epoch in range(1, number_epoch+1):\n",
    "          for i, (inputs, labels) in enumerate(train_loader):  \n",
    "              inputs = inputs.to(device=device)\n",
    "              labels = labels.to(device=device)          \n",
    "              optimizer.zero_grad()\n",
    "              outputs = model_fnn(inputs)\n",
    "              loss = criterion(outputs, labels)\n",
    "              loss.backward()\n",
    "              optimizer.step()\n",
    "              if i % 10 == 0:\n",
    "                  # if num_without_imp > 30:\n",
    "                  #     return model_fnn\n",
    "                  num_without_imp = num_without_imp + 1\n",
    "                  valid_losses = list()\n",
    "                  model_fnn.eval()\n",
    "                  for inp, lab in valid_loader:\n",
    "                      inp = inp.to(device)\n",
    "                      lab = lab.to(device)\n",
    "                      out = model_fnn(inp)\n",
    "                      valid_loss = criterion(out, lab)\n",
    "                      valid_losses.append(valid_loss.item())\n",
    "                  \n",
    "                  model_fnn.train()\n",
    "                  print(\"Epoch: {}/{}...\".format(epoch, number_epoch),\n",
    "                      \"Step: {}/{}...\".format(i+1, len(train_dataset)//batch_size),\n",
    "                      \"Loss: {:.8f}...\".format(loss.item()),\n",
    "                      \"Valid Loss: {:.8f}...\".format(np.mean(valid_losses)))\n",
    "                  if np.mean(valid_losses) < valid_loss_min:\n",
    "                      num_without_imp = 0\n",
    "                      torch.save(model_fnn.state_dict(), \"fnn_state_dict.pt\")\n",
    "                      print(\"Valid loss decreased ({:.6f}-->{:.6f}). Saving model...\".format(valid_loss_min, np.mean(valid_losses)))\n",
    "                      valid_loss_min = np.mean(valid_losses)\n",
    "    return model_fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1635325087004,
     "user": {
      "displayName": "Mark Dong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04537685704836554558"
     },
     "user_tz": -480
    },
    "id": "AS1RZ_wEtS30"
   },
   "outputs": [],
   "source": [
    "# test model by day\n",
    "def Test_Model_24(model, test_x, test_y, batch_size, seq_len, y_col_index, scaler):\n",
    "    test_dataset = TensorDataset(torch.FloatTensor(test_x), torch.FloatTensor(test_y))\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    model.load_state_dict(torch.load('fnn_state_dict.pt'))\n",
    "    size = 24\n",
    "    y_pred = list()\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = inputs.to(device=device)\n",
    "            inp = inputs.reshape(inputs.shape[0], -1)\n",
    "            out = model(inp)\n",
    "            y_pred = y_pred + out.cpu().numpy().tolist()\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(test_y)\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "    y_true = y_true.reshape(-1, 1)    \n",
    "    load_pred = scaler.inverse_transform(y_pred)\n",
    "    load_true = scaler.inverse_transform(y_true)\n",
    "    MAPE = np.mean(np.abs(load_true-load_pred)/load_true)\n",
    "    MAE = np.mean(np.abs(load_true-load_pred))\n",
    "    RMSE = np.sqrt(np.mean(np.square(load_true-load_pred)))\n",
    "    return MAPE, MAE, RMSE, load_pred, load_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1635324243558,
     "user": {
      "displayName": "Mark Dong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04537685704836554558"
     },
     "user_tz": -480
    },
    "id": "hqlFR9TCtS30"
   },
   "outputs": [],
   "source": [
    "# model configs\n",
    "def Model_Configs():\n",
    "    batch_sizes = [512]\n",
    "    lrs = [0.01]\n",
    "    number_epochs = [50]\n",
    "    hidden_dims = [5]\n",
    "    configs = list()\n",
    "    for i in batch_sizes:\n",
    "        for j in lrs:\n",
    "            for k in number_epochs:\n",
    "                for l in hidden_dims:\n",
    "                    configs.append([i, j ,k ,l])\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1635327597138,
     "user": {
      "displayName": "Mark Dong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04537685704836554558"
     },
     "user_tz": -480
    },
    "id": "ksq14TXuY661"
   },
   "outputs": [],
   "source": [
    "def main(seq_len=48):\n",
    "    # 归一化\n",
    "    normalized_data, scaler_y = normalization(data)\n",
    "    train_data = normalized_data\n",
    "    test_data = normalized_data[-5496:]\n",
    "    # 数据处理，将时间序列数据变为监督学习数据\n",
    "    y_index = data.shape[1] -1\n",
    "    input_size = data.shape[1] * seq_len\n",
    "    X_train, Y_train = Series_To_Supervise(train_data, seq_len=seq_len, y_col_index=y_index)\n",
    "\n",
    "    # 五折交叉验证，划分数据集\n",
    "    train_x_list, valid_x_list, train_y_list, valid_y_list = split_dataset(X_train, Y_train)\n",
    "    test_x, test_y = Series_To_Supervise_Test(test_data, seq_len=seq_len, y_col_index=y_index)\n",
    "    print(\"model configs set\")\n",
    "    configs = Model_Configs()\n",
    "    MAPE_list = list()\n",
    "    MAE_list = list()\n",
    "    RMSE_list = list()\n",
    "    for config in configs:\n",
    "        batch_size = config[0]\n",
    "        lr = config[1]\n",
    "        number_epoch = config[2]\n",
    "        hidden_dim = config[3]\n",
    "        print(\"Config: batch_size--{}, lr--{}, number_epoch--{}, hidden_dim--{}\".format(config[0], config[1], config[2], config[3]))\n",
    "        while(1):\n",
    "          model = Train_Model(train_x_list, train_y_list, valid_x_list, valid_y_list, batch_size, lr, number_epoch,\n",
    "                              input_size=input_size, hidden_dim=hidden_dim, seq_len=seq_len,)\n",
    "          MAPE, MAE, RMSE, load_pred, load_true = Test_Model_24(model, test_x, test_y, batch_size, seq_len,\n",
    "                                          y_col_index=y_index, scaler=scaler_y)\n",
    "          if MAPE < 1:\n",
    "            break\n",
    "        MAPE_list.append(MAPE)\n",
    "        MAE_list.append(MAE)\n",
    "        RMSE_list.append(RMSE)\n",
    "    return (MAPE_list, MAE_list, RMSE_list, load_pred, load_true, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 149832,
     "status": "ok",
     "timestamp": 1635327753206,
     "user": {
      "displayName": "Mark Dong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04537685704836554558"
     },
     "user_tz": -480
    },
    "id": "QlXRJj0etS31",
    "outputId": "bdd48c50-018d-414a-dc12-b4f48b1a73fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x: (31587, 48, 23), shape of y: (31587, 24)\n",
      "shape of x: (227, 48, 23), shape of y: (227, 24)\n",
      "model configs set\n",
      "Config: batch_size--512, lr--0.01, number_epoch--40, hidden_dim--5\n",
      "train dataset 0\n",
      "Epoch: 1/40... Step: 1/49... Loss: 0.15357873... Valid Loss: 8.17134351...\n",
      "Valid loss decreased (inf-->8.171344). Saving model...\n",
      "Epoch: 1/40... Step: 11/49... Loss: 0.09921432... Valid Loss: 0.09933239...\n",
      "Valid loss decreased (8.171344-->0.099332). Saving model...\n",
      "Epoch: 1/40... Step: 21/49... Loss: 0.07201394... Valid Loss: 0.06628665...\n",
      "Valid loss decreased (0.099332-->0.066287). Saving model...\n",
      "Epoch: 1/40... Step: 31/49... Loss: 0.05727912... Valid Loss: 0.05533390...\n",
      "Valid loss decreased (0.066287-->0.055334). Saving model...\n",
      "Epoch: 1/40... Step: 41/49... Loss: 0.05094071... Valid Loss: 0.05151305...\n",
      "Valid loss decreased (0.055334-->0.051513). Saving model...\n",
      "Epoch: 2/40... Step: 1/49... Loss: 0.04971464... Valid Loss: 0.04927217...\n",
      "Valid loss decreased (0.051513-->0.049272). Saving model...\n",
      "Epoch: 2/40... Step: 11/49... Loss: 0.04962791... Valid Loss: 0.04816091...\n",
      "Valid loss decreased (0.049272-->0.048161). Saving model...\n",
      "Epoch: 2/40... Step: 21/49... Loss: 0.04822060... Valid Loss: 0.04782355...\n",
      "Valid loss decreased (0.048161-->0.047824). Saving model...\n",
      "Epoch: 2/40... Step: 31/49... Loss: 0.04895623... Valid Loss: 0.04776062...\n",
      "Valid loss decreased (0.047824-->0.047761). Saving model...\n",
      "Epoch: 2/40... Step: 41/49... Loss: 0.04806343... Valid Loss: 0.04762101...\n",
      "Valid loss decreased (0.047761-->0.047621). Saving model...\n",
      "Epoch: 3/40... Step: 1/49... Loss: 0.04922531... Valid Loss: 0.04786260...\n",
      "Epoch: 3/40... Step: 11/49... Loss: 0.04725550... Valid Loss: 0.04747115...\n",
      "Valid loss decreased (0.047621-->0.047471). Saving model...\n",
      "Epoch: 3/40... Step: 21/49... Loss: 0.04704417... Valid Loss: 0.04739896...\n",
      "Valid loss decreased (0.047471-->0.047399). Saving model...\n",
      "Epoch: 3/40... Step: 31/49... Loss: 0.04875937... Valid Loss: 0.04749203...\n",
      "Epoch: 3/40... Step: 41/49... Loss: 0.04897767... Valid Loss: 0.04791142...\n",
      "Epoch: 4/40... Step: 1/49... Loss: 0.04833348... Valid Loss: 0.04735283...\n",
      "Valid loss decreased (0.047399-->0.047353). Saving model...\n",
      "Epoch: 4/40... Step: 11/49... Loss: 0.04780358... Valid Loss: 0.04733166...\n",
      "Valid loss decreased (0.047353-->0.047332). Saving model...\n",
      "Epoch: 4/40... Step: 21/49... Loss: 0.04551847... Valid Loss: 0.04752471...\n",
      "Epoch: 4/40... Step: 31/49... Loss: 0.04660482... Valid Loss: 0.04758417...\n",
      "Epoch: 4/40... Step: 41/49... Loss: 0.04762602... Valid Loss: 0.04733356...\n",
      "Epoch: 5/40... Step: 1/49... Loss: 0.04874647... Valid Loss: 0.04757772...\n",
      "Epoch: 5/40... Step: 11/49... Loss: 0.04762766... Valid Loss: 0.04717859...\n",
      "Valid loss decreased (0.047332-->0.047179). Saving model...\n",
      "Epoch: 5/40... Step: 21/49... Loss: 0.04809481... Valid Loss: 0.04721353...\n",
      "Epoch: 5/40... Step: 31/49... Loss: 0.04637007... Valid Loss: 0.04730070...\n",
      "Epoch: 5/40... Step: 41/49... Loss: 0.04676316... Valid Loss: 0.04807292...\n",
      "Epoch: 6/40... Step: 1/49... Loss: 0.04669387... Valid Loss: 0.04736622...\n",
      "Epoch: 6/40... Step: 11/49... Loss: 0.04428679... Valid Loss: 0.04721664...\n",
      "Epoch: 6/40... Step: 21/49... Loss: 0.05051903... Valid Loss: 0.04719314...\n",
      "Epoch: 6/40... Step: 31/49... Loss: 0.04724190... Valid Loss: 0.04748878...\n",
      "Epoch: 6/40... Step: 41/49... Loss: 0.04892786... Valid Loss: 0.04730115...\n",
      "Epoch: 7/40... Step: 1/49... Loss: 0.04991356... Valid Loss: 0.04712627...\n",
      "Valid loss decreased (0.047179-->0.047126). Saving model...\n",
      "Epoch: 7/40... Step: 11/49... Loss: 0.04791237... Valid Loss: 0.04721987...\n",
      "Epoch: 7/40... Step: 21/49... Loss: 0.04841946... Valid Loss: 0.04730406...\n",
      "Epoch: 7/40... Step: 31/49... Loss: 0.04735739... Valid Loss: 0.04719847...\n",
      "Epoch: 7/40... Step: 41/49... Loss: 0.04891663... Valid Loss: 0.04749690...\n",
      "Epoch: 8/40... Step: 1/49... Loss: 0.04637051... Valid Loss: 0.04715381...\n",
      "Epoch: 8/40... Step: 11/49... Loss: 0.04876731... Valid Loss: 0.04770221...\n",
      "Epoch: 8/40... Step: 21/49... Loss: 0.04891577... Valid Loss: 0.04720604...\n",
      "Epoch: 8/40... Step: 31/49... Loss: 0.04806338... Valid Loss: 0.04721061...\n",
      "Epoch: 8/40... Step: 41/49... Loss: 0.04828079... Valid Loss: 0.04741422...\n",
      "Epoch: 9/40... Step: 1/49... Loss: 0.04884132... Valid Loss: 0.04708528...\n",
      "Valid loss decreased (0.047126-->0.047085). Saving model...\n",
      "Epoch: 9/40... Step: 11/49... Loss: 0.04798996... Valid Loss: 0.04746321...\n",
      "Epoch: 9/40... Step: 21/49... Loss: 0.04751169... Valid Loss: 0.04713009...\n",
      "Epoch: 9/40... Step: 31/49... Loss: 0.04899625... Valid Loss: 0.04724441...\n",
      "Epoch: 9/40... Step: 41/49... Loss: 0.04603785... Valid Loss: 0.04723795...\n",
      "Epoch: 10/40... Step: 1/49... Loss: 0.04761684... Valid Loss: 0.04769358...\n",
      "Epoch: 10/40... Step: 11/49... Loss: 0.04627339... Valid Loss: 0.04698775...\n",
      "Valid loss decreased (0.047085-->0.046988). Saving model...\n",
      "Epoch: 10/40... Step: 21/49... Loss: 0.04588110... Valid Loss: 0.04745122...\n",
      "Epoch: 10/40... Step: 31/49... Loss: 0.04641375... Valid Loss: 0.04636407...\n",
      "Valid loss decreased (0.046988-->0.046364). Saving model...\n",
      "Epoch: 10/40... Step: 41/49... Loss: 0.04535515... Valid Loss: 0.04619609...\n",
      "Valid loss decreased (0.046364-->0.046196). Saving model...\n",
      "Epoch: 11/40... Step: 1/49... Loss: 0.03437202... Valid Loss: 0.03456359...\n",
      "Valid loss decreased (0.046196-->0.034564). Saving model...\n",
      "Epoch: 11/40... Step: 11/49... Loss: 0.03242968... Valid Loss: 0.03097838...\n",
      "Valid loss decreased (0.034564-->0.030978). Saving model...\n",
      "Epoch: 11/40... Step: 21/49... Loss: 0.03086520... Valid Loss: 0.03055612...\n",
      "Valid loss decreased (0.030978-->0.030556). Saving model...\n",
      "Epoch: 11/40... Step: 31/49... Loss: 0.03010932... Valid Loss: 0.03043497...\n",
      "Valid loss decreased (0.030556-->0.030435). Saving model...\n",
      "Epoch: 11/40... Step: 41/49... Loss: 0.02929420... Valid Loss: 0.02996701...\n",
      "Valid loss decreased (0.030435-->0.029967). Saving model...\n",
      "Epoch: 12/40... Step: 1/49... Loss: 0.03090460... Valid Loss: 0.03021640...\n",
      "Epoch: 12/40... Step: 11/49... Loss: 0.03103588... Valid Loss: 0.03084769...\n",
      "Epoch: 12/40... Step: 21/49... Loss: 0.03165220... Valid Loss: 0.02964792...\n",
      "Valid loss decreased (0.029967-->0.029648). Saving model...\n",
      "Epoch: 12/40... Step: 31/49... Loss: 0.02993900... Valid Loss: 0.02951211...\n",
      "Valid loss decreased (0.029648-->0.029512). Saving model...\n",
      "Epoch: 12/40... Step: 41/49... Loss: 0.03133781... Valid Loss: 0.02964067...\n",
      "Epoch: 13/40... Step: 1/49... Loss: 0.02969974... Valid Loss: 0.02971584...\n",
      "Epoch: 13/40... Step: 11/49... Loss: 0.02934062... Valid Loss: 0.02965760...\n",
      "Epoch: 13/40... Step: 21/49... Loss: 0.03071877... Valid Loss: 0.02964732...\n",
      "Epoch: 13/40... Step: 31/49... Loss: 0.02983455... Valid Loss: 0.02924613...\n",
      "Valid loss decreased (0.029512-->0.029246). Saving model...\n",
      "Epoch: 13/40... Step: 41/49... Loss: 0.02835605... Valid Loss: 0.02913596...\n",
      "Valid loss decreased (0.029246-->0.029136). Saving model...\n",
      "Epoch: 14/40... Step: 1/49... Loss: 0.02932647... Valid Loss: 0.02934872...\n",
      "Epoch: 14/40... Step: 11/49... Loss: 0.02989776... Valid Loss: 0.02911239...\n",
      "Valid loss decreased (0.029136-->0.029112). Saving model...\n",
      "Epoch: 14/40... Step: 21/49... Loss: 0.02803831... Valid Loss: 0.02921430...\n",
      "Epoch: 14/40... Step: 31/49... Loss: 0.02827436... Valid Loss: 0.02927248...\n",
      "Epoch: 14/40... Step: 41/49... Loss: 0.02852584... Valid Loss: 0.02917364...\n",
      "Epoch: 15/40... Step: 1/49... Loss: 0.02848213... Valid Loss: 0.02903410...\n",
      "Valid loss decreased (0.029112-->0.029034). Saving model...\n",
      "Epoch: 15/40... Step: 11/49... Loss: 0.03062719... Valid Loss: 0.02910218...\n",
      "Epoch: 15/40... Step: 21/49... Loss: 0.02880778... Valid Loss: 0.02911341...\n",
      "Epoch: 15/40... Step: 31/49... Loss: 0.02844950... Valid Loss: 0.02883312...\n",
      "Valid loss decreased (0.029034-->0.028833). Saving model...\n",
      "Epoch: 15/40... Step: 41/49... Loss: 0.02984690... Valid Loss: 0.02882443...\n",
      "Valid loss decreased (0.028833-->0.028824). Saving model...\n",
      "Epoch: 16/40... Step: 1/49... Loss: 0.02837228... Valid Loss: 0.02867530...\n",
      "Valid loss decreased (0.028824-->0.028675). Saving model...\n",
      "Epoch: 16/40... Step: 11/49... Loss: 0.03121733... Valid Loss: 0.02949522...\n",
      "Epoch: 16/40... Step: 21/49... Loss: 0.02838734... Valid Loss: 0.02882156...\n",
      "Epoch: 16/40... Step: 31/49... Loss: 0.02970485... Valid Loss: 0.02864066...\n",
      "Valid loss decreased (0.028675-->0.028641). Saving model...\n",
      "Epoch: 16/40... Step: 41/49... Loss: 0.02945401... Valid Loss: 0.02884349...\n",
      "Epoch: 17/40... Step: 1/49... Loss: 0.02892824... Valid Loss: 0.02840091...\n",
      "Valid loss decreased (0.028641-->0.028401). Saving model...\n",
      "Epoch: 17/40... Step: 11/49... Loss: 0.02890127... Valid Loss: 0.02874261...\n",
      "Epoch: 17/40... Step: 21/49... Loss: 0.02856357... Valid Loss: 0.02842310...\n",
      "Epoch: 17/40... Step: 31/49... Loss: 0.02960236... Valid Loss: 0.02818240...\n",
      "Valid loss decreased (0.028401-->0.028182). Saving model...\n",
      "Epoch: 17/40... Step: 41/49... Loss: 0.02975210... Valid Loss: 0.02826719...\n",
      "Epoch: 18/40... Step: 1/49... Loss: 0.02812541... Valid Loss: 0.02815166...\n",
      "Valid loss decreased (0.028182-->0.028152). Saving model...\n",
      "Epoch: 18/40... Step: 11/49... Loss: 0.02940160... Valid Loss: 0.02798194...\n",
      "Valid loss decreased (0.028152-->0.027982). Saving model...\n",
      "Epoch: 18/40... Step: 21/49... Loss: 0.02885260... Valid Loss: 0.02785387...\n",
      "Valid loss decreased (0.027982-->0.027854). Saving model...\n",
      "Epoch: 18/40... Step: 31/49... Loss: 0.02829293... Valid Loss: 0.02795629...\n",
      "Epoch: 18/40... Step: 41/49... Loss: 0.02755605... Valid Loss: 0.02768229...\n",
      "Valid loss decreased (0.027854-->0.027682). Saving model...\n",
      "Epoch: 19/40... Step: 1/49... Loss: 0.02837272... Valid Loss: 0.02780822...\n",
      "Epoch: 19/40... Step: 11/49... Loss: 0.02933653... Valid Loss: 0.02834809...\n",
      "Epoch: 19/40... Step: 21/49... Loss: 0.02777072... Valid Loss: 0.02769411...\n",
      "Epoch: 19/40... Step: 31/49... Loss: 0.02938240... Valid Loss: 0.02822110...\n",
      "Epoch: 19/40... Step: 41/49... Loss: 0.02687337... Valid Loss: 0.02758147...\n",
      "Valid loss decreased (0.027682-->0.027581). Saving model...\n",
      "Epoch: 20/40... Step: 1/49... Loss: 0.02754425... Valid Loss: 0.02857123...\n",
      "Epoch: 20/40... Step: 11/49... Loss: 0.02878525... Valid Loss: 0.02760906...\n",
      "Epoch: 20/40... Step: 21/49... Loss: 0.02541301... Valid Loss: 0.02700029...\n",
      "Valid loss decreased (0.027581-->0.027000). Saving model...\n",
      "Epoch: 20/40... Step: 31/49... Loss: 0.02731900... Valid Loss: 0.02884336...\n",
      "Epoch: 20/40... Step: 41/49... Loss: 0.02534783... Valid Loss: 0.02799575...\n",
      "Epoch: 21/40... Step: 1/49... Loss: 0.02719744... Valid Loss: 0.02693583...\n",
      "Valid loss decreased (0.027000-->0.026936). Saving model...\n",
      "Epoch: 21/40... Step: 11/49... Loss: 0.02635123... Valid Loss: 0.02712741...\n",
      "Epoch: 21/40... Step: 21/49... Loss: 0.02803878... Valid Loss: 0.02787461...\n",
      "Epoch: 21/40... Step: 31/49... Loss: 0.02787044... Valid Loss: 0.02682677...\n",
      "Valid loss decreased (0.026936-->0.026827). Saving model...\n",
      "Epoch: 21/40... Step: 41/49... Loss: 0.02682143... Valid Loss: 0.02653306...\n",
      "Valid loss decreased (0.026827-->0.026533). Saving model...\n",
      "Epoch: 22/40... Step: 1/49... Loss: 0.02684321... Valid Loss: 0.02681264...\n",
      "Epoch: 22/40... Step: 11/49... Loss: 0.02707409... Valid Loss: 0.02628316...\n",
      "Valid loss decreased (0.026533-->0.026283). Saving model...\n",
      "Epoch: 22/40... Step: 21/49... Loss: 0.02935329... Valid Loss: 0.02802465...\n",
      "Epoch: 22/40... Step: 31/49... Loss: 0.02873246... Valid Loss: 0.02646511...\n",
      "Epoch: 22/40... Step: 41/49... Loss: 0.02687164... Valid Loss: 0.02713360...\n",
      "Epoch: 23/40... Step: 1/49... Loss: 0.02819014... Valid Loss: 0.02766406...\n",
      "Epoch: 23/40... Step: 11/49... Loss: 0.02654256... Valid Loss: 0.02626468...\n",
      "Valid loss decreased (0.026283-->0.026265). Saving model...\n",
      "Epoch: 23/40... Step: 21/49... Loss: 0.02603352... Valid Loss: 0.02603046...\n",
      "Valid loss decreased (0.026265-->0.026030). Saving model...\n",
      "Epoch: 23/40... Step: 31/49... Loss: 0.02719525... Valid Loss: 0.02605605...\n",
      "Epoch: 23/40... Step: 41/49... Loss: 0.02502571... Valid Loss: 0.02699789...\n",
      "Epoch: 24/40... Step: 1/49... Loss: 0.02701990... Valid Loss: 0.02637421...\n",
      "Epoch: 24/40... Step: 11/49... Loss: 0.02622806... Valid Loss: 0.02590432...\n",
      "Valid loss decreased (0.026030-->0.025904). Saving model...\n",
      "Epoch: 24/40... Step: 21/49... Loss: 0.02536207... Valid Loss: 0.02602722...\n",
      "Epoch: 24/40... Step: 31/49... Loss: 0.02733466... Valid Loss: 0.02569941...\n",
      "Valid loss decreased (0.025904-->0.025699). Saving model...\n",
      "Epoch: 24/40... Step: 41/49... Loss: 0.02668652... Valid Loss: 0.02644972...\n",
      "Epoch: 25/40... Step: 1/49... Loss: 0.02679514... Valid Loss: 0.02592265...\n",
      "Epoch: 25/40... Step: 11/49... Loss: 0.02564981... Valid Loss: 0.02622712...\n",
      "Epoch: 25/40... Step: 21/49... Loss: 0.02634799... Valid Loss: 0.02697517...\n",
      "Epoch: 25/40... Step: 31/49... Loss: 0.02657576... Valid Loss: 0.02754781...\n",
      "Epoch: 25/40... Step: 41/49... Loss: 0.02626142... Valid Loss: 0.02574186...\n",
      "Epoch: 26/40... Step: 1/49... Loss: 0.02714736... Valid Loss: 0.02576161...\n",
      "Epoch: 26/40... Step: 11/49... Loss: 0.02656826... Valid Loss: 0.02637786...\n",
      "Epoch: 26/40... Step: 21/49... Loss: 0.02582297... Valid Loss: 0.02587177...\n",
      "Epoch: 26/40... Step: 31/49... Loss: 0.02776510... Valid Loss: 0.02573582...\n",
      "Epoch: 26/40... Step: 41/49... Loss: 0.02579265... Valid Loss: 0.02561600...\n",
      "Valid loss decreased (0.025699-->0.025616). Saving model...\n",
      "Epoch: 27/40... Step: 1/49... Loss: 0.02578119... Valid Loss: 0.02547342...\n",
      "Valid loss decreased (0.025616-->0.025473). Saving model...\n",
      "Epoch: 27/40... Step: 11/49... Loss: 0.02773108... Valid Loss: 0.02590238...\n",
      "Epoch: 27/40... Step: 21/49... Loss: 0.02670192... Valid Loss: 0.02542861...\n",
      "Valid loss decreased (0.025473-->0.025429). Saving model...\n",
      "Epoch: 27/40... Step: 31/49... Loss: 0.02015501... Valid Loss: 0.01879975...\n",
      "Valid loss decreased (0.025429-->0.018800). Saving model...\n",
      "Epoch: 27/40... Step: 41/49... Loss: 0.02024024... Valid Loss: 0.01903538...\n",
      "Epoch: 28/40... Step: 1/49... Loss: 0.02060868... Valid Loss: 0.01923348...\n",
      "Epoch: 28/40... Step: 11/49... Loss: 0.01895584... Valid Loss: 0.01959956...\n",
      "Epoch: 28/40... Step: 21/49... Loss: 0.01863510... Valid Loss: 0.01883896...\n",
      "Epoch: 28/40... Step: 31/49... Loss: 0.02021316... Valid Loss: 0.01930356...\n",
      "Epoch: 28/40... Step: 41/49... Loss: 0.01878828... Valid Loss: 0.01852155...\n",
      "Valid loss decreased (0.018800-->0.018522). Saving model...\n",
      "Epoch: 29/40... Step: 1/49... Loss: 0.02045874... Valid Loss: 0.01949450...\n",
      "Epoch: 29/40... Step: 11/49... Loss: 0.01830639... Valid Loss: 0.01836431...\n",
      "Valid loss decreased (0.018522-->0.018364). Saving model...\n",
      "Epoch: 29/40... Step: 21/49... Loss: 0.01825986... Valid Loss: 0.01914165...\n",
      "Epoch: 29/40... Step: 31/49... Loss: 0.01963249... Valid Loss: 0.01891001...\n",
      "Epoch: 29/40... Step: 41/49... Loss: 0.01304438... Valid Loss: 0.01342213...\n",
      "Valid loss decreased (0.018364-->0.013422). Saving model...\n",
      "Epoch: 30/40... Step: 1/49... Loss: 0.01222956... Valid Loss: 0.01221427...\n",
      "Valid loss decreased (0.013422-->0.012214). Saving model...\n",
      "Epoch: 30/40... Step: 11/49... Loss: 0.01301654... Valid Loss: 0.01161876...\n",
      "Valid loss decreased (0.012214-->0.011619). Saving model...\n",
      "Epoch: 30/40... Step: 21/49... Loss: 0.01225439... Valid Loss: 0.01122658...\n",
      "Valid loss decreased (0.011619-->0.011227). Saving model...\n",
      "Epoch: 30/40... Step: 31/49... Loss: 0.01166667... Valid Loss: 0.01141925...\n",
      "Epoch: 30/40... Step: 41/49... Loss: 0.01130142... Valid Loss: 0.01115357...\n",
      "Valid loss decreased (0.011227-->0.011154). Saving model...\n",
      "Epoch: 31/40... Step: 1/49... Loss: 0.01106243... Valid Loss: 0.01146754...\n",
      "Epoch: 31/40... Step: 11/49... Loss: 0.01204985... Valid Loss: 0.01111656...\n",
      "Valid loss decreased (0.011154-->0.011117). Saving model...\n",
      "Epoch: 31/40... Step: 21/49... Loss: 0.01190431... Valid Loss: 0.01162608...\n",
      "Epoch: 31/40... Step: 31/49... Loss: 0.01151978... Valid Loss: 0.01136320...\n",
      "Epoch: 31/40... Step: 41/49... Loss: 0.01144367... Valid Loss: 0.01210827...\n",
      "Epoch: 32/40... Step: 1/49... Loss: 0.01188579... Valid Loss: 0.01309029...\n",
      "Epoch: 32/40... Step: 11/49... Loss: 0.01243729... Valid Loss: 0.01127182...\n",
      "Epoch: 32/40... Step: 21/49... Loss: 0.01274966... Valid Loss: 0.01160418...\n",
      "Epoch: 32/40... Step: 31/49... Loss: 0.01134693... Valid Loss: 0.01189184...\n",
      "Epoch: 32/40... Step: 41/49... Loss: 0.01150150... Valid Loss: 0.01110762...\n",
      "Valid loss decreased (0.011117-->0.011108). Saving model...\n",
      "Epoch: 33/40... Step: 1/49... Loss: 0.01130421... Valid Loss: 0.01181904...\n",
      "Epoch: 33/40... Step: 11/49... Loss: 0.01189387... Valid Loss: 0.01091219...\n",
      "Valid loss decreased (0.011108-->0.010912). Saving model...\n",
      "Epoch: 33/40... Step: 21/49... Loss: 0.01187347... Valid Loss: 0.01227915...\n",
      "Epoch: 33/40... Step: 31/49... Loss: 0.01158048... Valid Loss: 0.01122545...\n",
      "Epoch: 33/40... Step: 41/49... Loss: 0.01064184... Valid Loss: 0.01135263...\n",
      "Epoch: 34/40... Step: 1/49... Loss: 0.01155690... Valid Loss: 0.01107259...\n",
      "Epoch: 34/40... Step: 11/49... Loss: 0.01137156... Valid Loss: 0.01114892...\n",
      "Epoch: 34/40... Step: 21/49... Loss: 0.01231758... Valid Loss: 0.01146585...\n",
      "Epoch: 34/40... Step: 31/49... Loss: 0.01093659... Valid Loss: 0.01113319...\n",
      "Epoch: 34/40... Step: 41/49... Loss: 0.01152923... Valid Loss: 0.01145423...\n",
      "Epoch: 35/40... Step: 1/49... Loss: 0.01096369... Valid Loss: 0.01106180...\n",
      "Epoch: 35/40... Step: 11/49... Loss: 0.01095522... Valid Loss: 0.01080871...\n",
      "Valid loss decreased (0.010912-->0.010809). Saving model...\n",
      "Epoch: 35/40... Step: 21/49... Loss: 0.01118146... Valid Loss: 0.01090875...\n",
      "Epoch: 35/40... Step: 31/49... Loss: 0.01066580... Valid Loss: 0.01083797...\n",
      "Epoch: 35/40... Step: 41/49... Loss: 0.01101699... Valid Loss: 0.01088823...\n",
      "Epoch: 36/40... Step: 1/49... Loss: 0.01137774... Valid Loss: 0.01187274...\n",
      "Epoch: 36/40... Step: 11/49... Loss: 0.01210118... Valid Loss: 0.01232687...\n",
      "Epoch: 36/40... Step: 21/49... Loss: 0.01092347... Valid Loss: 0.01153540...\n",
      "Epoch: 36/40... Step: 31/49... Loss: 0.01156525... Valid Loss: 0.01103956...\n",
      "Epoch: 36/40... Step: 41/49... Loss: 0.01101228... Valid Loss: 0.01071202...\n",
      "Valid loss decreased (0.010809-->0.010712). Saving model...\n",
      "Epoch: 37/40... Step: 1/49... Loss: 0.01094246... Valid Loss: 0.01099672...\n",
      "Epoch: 37/40... Step: 11/49... Loss: 0.01092176... Valid Loss: 0.01104699...\n",
      "Epoch: 37/40... Step: 21/49... Loss: 0.01096274... Valid Loss: 0.01075663...\n",
      "Epoch: 37/40... Step: 31/49... Loss: 0.01096987... Valid Loss: 0.01079561...\n",
      "Epoch: 37/40... Step: 41/49... Loss: 0.01029155... Valid Loss: 0.01062681...\n",
      "Valid loss decreased (0.010712-->0.010627). Saving model...\n",
      "Epoch: 38/40... Step: 1/49... Loss: 0.01288045... Valid Loss: 0.01104624...\n",
      "Epoch: 38/40... Step: 11/49... Loss: 0.01096475... Valid Loss: 0.01110101...\n",
      "Epoch: 38/40... Step: 21/49... Loss: 0.01083273... Valid Loss: 0.01111479...\n",
      "Epoch: 38/40... Step: 31/49... Loss: 0.01104321... Valid Loss: 0.01108548...\n",
      "Epoch: 38/40... Step: 41/49... Loss: 0.01117966... Valid Loss: 0.01125029...\n",
      "Epoch: 39/40... Step: 1/49... Loss: 0.01117583... Valid Loss: 0.01126027...\n",
      "Epoch: 39/40... Step: 11/49... Loss: 0.01099393... Valid Loss: 0.01083605...\n",
      "Epoch: 39/40... Step: 21/49... Loss: 0.01269853... Valid Loss: 0.01116317...\n",
      "Epoch: 39/40... Step: 31/49... Loss: 0.01094697... Valid Loss: 0.01132551...\n",
      "Epoch: 39/40... Step: 41/49... Loss: 0.01101436... Valid Loss: 0.01130805...\n",
      "Epoch: 40/40... Step: 1/49... Loss: 0.01038427... Valid Loss: 0.01076709...\n",
      "Epoch: 40/40... Step: 11/49... Loss: 0.01104940... Valid Loss: 0.01062275...\n",
      "Valid loss decreased (0.010627-->0.010623). Saving model...\n",
      "Epoch: 40/40... Step: 21/49... Loss: 0.01063805... Valid Loss: 0.01065727...\n",
      "Epoch: 40/40... Step: 31/49... Loss: 0.01064390... Valid Loss: 0.01064590...\n",
      "Epoch: 40/40... Step: 41/49... Loss: 0.01030622... Valid Loss: 0.01153411...\n",
      "train dataset 1\n",
      "Epoch: 1/40... Step: 1/49... Loss: 0.01223532... Valid Loss: 0.01124779...\n",
      "Epoch: 1/40... Step: 11/49... Loss: 0.01143970... Valid Loss: 0.01082307...\n",
      "Epoch: 1/40... Step: 21/49... Loss: 0.01023991... Valid Loss: 0.01065693...\n",
      "Epoch: 1/40... Step: 31/49... Loss: 0.01087552... Valid Loss: 0.01689620...\n",
      "Epoch: 1/40... Step: 41/49... Loss: 0.02256563... Valid Loss: 0.01956989...\n",
      "Epoch: 2/40... Step: 1/49... Loss: 0.01836303... Valid Loss: 0.01614291...\n",
      "Epoch: 2/40... Step: 11/49... Loss: 0.01357668... Valid Loss: 0.01375187...\n",
      "Epoch: 2/40... Step: 21/49... Loss: 0.01197722... Valid Loss: 0.01211703...\n",
      "Epoch: 2/40... Step: 31/49... Loss: 0.01204212... Valid Loss: 0.01148120...\n",
      "Epoch: 2/40... Step: 41/49... Loss: 0.01158744... Valid Loss: 0.01141152...\n",
      "Epoch: 3/40... Step: 1/49... Loss: 0.01111194... Valid Loss: 0.01137936...\n",
      "Epoch: 3/40... Step: 11/49... Loss: 0.01099539... Valid Loss: 0.01103856...\n",
      "Epoch: 3/40... Step: 21/49... Loss: 0.01172999... Valid Loss: 0.01084250...\n",
      "Epoch: 3/40... Step: 31/49... Loss: 0.01069138... Valid Loss: 0.01106342...\n",
      "Epoch: 3/40... Step: 41/49... Loss: 0.01058994... Valid Loss: 0.01085603...\n",
      "Epoch: 4/40... Step: 1/49... Loss: 0.01113934... Valid Loss: 0.01105761...\n",
      "Epoch: 4/40... Step: 11/49... Loss: 0.01083503... Valid Loss: 0.01071258...\n",
      "Epoch: 4/40... Step: 21/49... Loss: 0.01059348... Valid Loss: 0.01090507...\n",
      "Epoch: 4/40... Step: 31/49... Loss: 0.01117406... Valid Loss: 0.01079708...\n",
      "Epoch: 4/40... Step: 41/49... Loss: 0.01155035... Valid Loss: 0.01101355...\n",
      "Epoch: 5/40... Step: 1/49... Loss: 0.01110967... Valid Loss: 0.01070886...\n",
      "Epoch: 5/40... Step: 11/49... Loss: 0.01119956... Valid Loss: 0.01078271...\n",
      "Epoch: 5/40... Step: 21/49... Loss: 0.01126544... Valid Loss: 0.01063145...\n",
      "Epoch: 5/40... Step: 31/49... Loss: 0.00994444... Valid Loss: 0.01074471...\n",
      "Epoch: 5/40... Step: 41/49... Loss: 0.01130433... Valid Loss: 0.01063084...\n",
      "Epoch: 6/40... Step: 1/49... Loss: 0.01094522... Valid Loss: 0.01093242...\n",
      "Epoch: 6/40... Step: 11/49... Loss: 0.01104439... Valid Loss: 0.01084662...\n",
      "Epoch: 6/40... Step: 21/49... Loss: 0.01028880... Valid Loss: 0.01100870...\n",
      "Epoch: 6/40... Step: 31/49... Loss: 0.01056722... Valid Loss: 0.01068909...\n",
      "Epoch: 6/40... Step: 41/49... Loss: 0.01035271... Valid Loss: 0.01063536...\n",
      "Epoch: 7/40... Step: 1/49... Loss: 0.01094889... Valid Loss: 0.01077177...\n",
      "Epoch: 7/40... Step: 11/49... Loss: 0.01051127... Valid Loss: 0.01056271...\n",
      "Valid loss decreased (0.010623-->0.010563). Saving model...\n",
      "Epoch: 7/40... Step: 21/49... Loss: 0.01063054... Valid Loss: 0.01078948...\n",
      "Epoch: 7/40... Step: 31/49... Loss: 0.01090885... Valid Loss: 0.01068557...\n",
      "Epoch: 7/40... Step: 41/49... Loss: 0.01128998... Valid Loss: 0.01149103...\n",
      "Epoch: 8/40... Step: 1/49... Loss: 0.01096039... Valid Loss: 0.01074065...\n",
      "Epoch: 8/40... Step: 11/49... Loss: 0.01111688... Valid Loss: 0.01097422...\n",
      "Epoch: 8/40... Step: 21/49... Loss: 0.01041768... Valid Loss: 0.01077130...\n",
      "Epoch: 8/40... Step: 31/49... Loss: 0.01133132... Valid Loss: 0.01090698...\n",
      "Epoch: 8/40... Step: 41/49... Loss: 0.01120961... Valid Loss: 0.01069232...\n",
      "Epoch: 9/40... Step: 1/49... Loss: 0.01216263... Valid Loss: 0.01212373...\n",
      "Epoch: 9/40... Step: 11/49... Loss: 0.01167938... Valid Loss: 0.01136419...\n",
      "Epoch: 9/40... Step: 21/49... Loss: 0.01102069... Valid Loss: 0.01155332...\n",
      "Epoch: 9/40... Step: 31/49... Loss: 0.01111694... Valid Loss: 0.01122049...\n",
      "Epoch: 9/40... Step: 41/49... Loss: 0.01011774... Valid Loss: 0.01067223...\n",
      "Epoch: 10/40... Step: 1/49... Loss: 0.01037798... Valid Loss: 0.01058794...\n",
      "Epoch: 10/40... Step: 11/49... Loss: 0.01083367... Valid Loss: 0.01063596...\n",
      "Epoch: 10/40... Step: 21/49... Loss: 0.01083083... Valid Loss: 0.01076246...\n",
      "Epoch: 10/40... Step: 31/49... Loss: 0.01080578... Valid Loss: 0.01097956...\n",
      "Epoch: 10/40... Step: 41/49... Loss: 0.01076699... Valid Loss: 0.01068161...\n",
      "Epoch: 11/40... Step: 1/49... Loss: 0.01103954... Valid Loss: 0.01092858...\n",
      "Epoch: 11/40... Step: 11/49... Loss: 0.01036980... Valid Loss: 0.01061996...\n",
      "Epoch: 11/40... Step: 21/49... Loss: 0.01031495... Valid Loss: 0.01074664...\n",
      "Epoch: 11/40... Step: 31/49... Loss: 0.01061857... Valid Loss: 0.01089193...\n",
      "Epoch: 11/40... Step: 41/49... Loss: 0.01018046... Valid Loss: 0.01055727...\n",
      "Valid loss decreased (0.010563-->0.010557). Saving model...\n",
      "Epoch: 12/40... Step: 1/49... Loss: 0.01029567... Valid Loss: 0.01083027...\n",
      "Epoch: 12/40... Step: 11/49... Loss: 0.01077706... Valid Loss: 0.01057688...\n",
      "Epoch: 12/40... Step: 21/49... Loss: 0.01119487... Valid Loss: 0.01062134...\n",
      "Epoch: 12/40... Step: 31/49... Loss: 0.01149619... Valid Loss: 0.01081132...\n",
      "Epoch: 12/40... Step: 41/49... Loss: 0.01106606... Valid Loss: 0.01083984...\n",
      "Epoch: 13/40... Step: 1/49... Loss: 0.01132854... Valid Loss: 0.01099262...\n",
      "Epoch: 13/40... Step: 11/49... Loss: 0.01055284... Valid Loss: 0.01123163...\n",
      "Epoch: 13/40... Step: 21/49... Loss: 0.01030907... Valid Loss: 0.01081010...\n",
      "Epoch: 13/40... Step: 31/49... Loss: 0.01138038... Valid Loss: 0.01096963...\n",
      "Epoch: 13/40... Step: 41/49... Loss: 0.01019339... Valid Loss: 0.01061166...\n",
      "Epoch: 14/40... Step: 1/49... Loss: 0.01039424... Valid Loss: 0.01057196...\n",
      "Epoch: 14/40... Step: 11/49... Loss: 0.01017035... Valid Loss: 0.01090262...\n",
      "Epoch: 14/40... Step: 21/49... Loss: 0.01077533... Valid Loss: 0.01058687...\n",
      "Epoch: 14/40... Step: 31/49... Loss: 0.01124555... Valid Loss: 0.01071063...\n",
      "Epoch: 14/40... Step: 41/49... Loss: 0.01099346... Valid Loss: 0.01132631...\n",
      "Epoch: 15/40... Step: 1/49... Loss: 0.01139110... Valid Loss: 0.01073346...\n",
      "Epoch: 15/40... Step: 11/49... Loss: 0.01104721... Valid Loss: 0.01128755...\n",
      "Epoch: 15/40... Step: 21/49... Loss: 0.01062443... Valid Loss: 0.01051524...\n",
      "Valid loss decreased (0.010557-->0.010515). Saving model...\n",
      "Epoch: 15/40... Step: 31/49... Loss: 0.01056655... Valid Loss: 0.01070315...\n",
      "Epoch: 15/40... Step: 41/49... Loss: 0.01064619... Valid Loss: 0.01055488...\n",
      "Epoch: 16/40... Step: 1/49... Loss: 0.01047534... Valid Loss: 0.01117508...\n",
      "Epoch: 16/40... Step: 11/49... Loss: 0.01101197... Valid Loss: 0.01068830...\n",
      "Epoch: 16/40... Step: 21/49... Loss: 0.01065156... Valid Loss: 0.01079575...\n",
      "Epoch: 16/40... Step: 31/49... Loss: 0.01052189... Valid Loss: 0.01084162...\n",
      "Epoch: 16/40... Step: 41/49... Loss: 0.00981970... Valid Loss: 0.01066792...\n",
      "Epoch: 17/40... Step: 1/49... Loss: 0.01092200... Valid Loss: 0.01062552...\n",
      "Epoch: 17/40... Step: 11/49... Loss: 0.01132466... Valid Loss: 0.01052231...\n",
      "Epoch: 17/40... Step: 21/49... Loss: 0.01039358... Valid Loss: 0.01062730...\n",
      "Epoch: 17/40... Step: 31/49... Loss: 0.01081219... Valid Loss: 0.01057801...\n",
      "Epoch: 17/40... Step: 41/49... Loss: 0.01088406... Valid Loss: 0.01051215...\n",
      "Valid loss decreased (0.010515-->0.010512). Saving model...\n",
      "Epoch: 18/40... Step: 1/49... Loss: 0.01047355... Valid Loss: 0.01048844...\n",
      "Valid loss decreased (0.010512-->0.010488). Saving model...\n",
      "Epoch: 18/40... Step: 11/49... Loss: 0.01025329... Valid Loss: 0.01059663...\n",
      "Epoch: 18/40... Step: 21/49... Loss: 0.01049497... Valid Loss: 0.01066988...\n",
      "Epoch: 18/40... Step: 31/49... Loss: 0.01091791... Valid Loss: 0.01129460...\n",
      "Epoch: 18/40... Step: 41/49... Loss: 0.01068117... Valid Loss: 0.01099145...\n",
      "Epoch: 19/40... Step: 1/49... Loss: 0.01064108... Valid Loss: 0.01052708...\n",
      "Epoch: 19/40... Step: 11/49... Loss: 0.01060426... Valid Loss: 0.01107837...\n",
      "Epoch: 19/40... Step: 21/49... Loss: 0.01081256... Valid Loss: 0.01078535...\n",
      "Epoch: 19/40... Step: 31/49... Loss: 0.01158261... Valid Loss: 0.01046870...\n",
      "Valid loss decreased (0.010488-->0.010469). Saving model...\n",
      "Epoch: 19/40... Step: 41/49... Loss: 0.01094891... Valid Loss: 0.01093022...\n",
      "Epoch: 20/40... Step: 1/49... Loss: 0.01037957... Valid Loss: 0.01067600...\n",
      "Epoch: 20/40... Step: 11/49... Loss: 0.01114809... Valid Loss: 0.01072147...\n",
      "Epoch: 20/40... Step: 21/49... Loss: 0.01076301... Valid Loss: 0.01052697...\n",
      "Epoch: 20/40... Step: 31/49... Loss: 0.01169880... Valid Loss: 0.01180579...\n",
      "Epoch: 20/40... Step: 41/49... Loss: 0.01066893... Valid Loss: 0.01075430...\n",
      "Epoch: 21/40... Step: 1/49... Loss: 0.01058210... Valid Loss: 0.01055694...\n",
      "Epoch: 21/40... Step: 11/49... Loss: 0.01088532... Valid Loss: 0.01071657...\n",
      "Epoch: 21/40... Step: 21/49... Loss: 0.01006983... Valid Loss: 0.01073185...\n",
      "Epoch: 21/40... Step: 31/49... Loss: 0.01108941... Valid Loss: 0.01072361...\n",
      "Epoch: 21/40... Step: 41/49... Loss: 0.01111070... Valid Loss: 0.01075413...\n",
      "Epoch: 22/40... Step: 1/49... Loss: 0.01066018... Valid Loss: 0.01072213...\n",
      "Epoch: 22/40... Step: 11/49... Loss: 0.01181387... Valid Loss: 0.01158586...\n",
      "Epoch: 22/40... Step: 21/49... Loss: 0.01169873... Valid Loss: 0.01269212...\n",
      "Epoch: 22/40... Step: 31/49... Loss: 0.01108202... Valid Loss: 0.01055002...\n",
      "Epoch: 22/40... Step: 41/49... Loss: 0.01047700... Valid Loss: 0.01107799...\n",
      "Epoch: 23/40... Step: 1/49... Loss: 0.01061677... Valid Loss: 0.01058869...\n",
      "Epoch: 23/40... Step: 11/49... Loss: 0.01062138... Valid Loss: 0.01053976...\n",
      "Epoch: 23/40... Step: 21/49... Loss: 0.01093744... Valid Loss: 0.01055686...\n",
      "Epoch: 23/40... Step: 31/49... Loss: 0.00983855... Valid Loss: 0.01056830...\n",
      "Epoch: 23/40... Step: 41/49... Loss: 0.01056120... Valid Loss: 0.01063747...\n",
      "Epoch: 24/40... Step: 1/49... Loss: 0.01146562... Valid Loss: 0.01088244...\n",
      "Epoch: 24/40... Step: 11/49... Loss: 0.01106851... Valid Loss: 0.01119485...\n",
      "Epoch: 24/40... Step: 21/49... Loss: 0.01120790... Valid Loss: 0.01124166...\n",
      "Epoch: 24/40... Step: 31/49... Loss: 0.01110828... Valid Loss: 0.01084794...\n",
      "Epoch: 24/40... Step: 41/49... Loss: 0.01035713... Valid Loss: 0.01056754...\n",
      "Epoch: 25/40... Step: 1/49... Loss: 0.01064483... Valid Loss: 0.01070619...\n",
      "Epoch: 25/40... Step: 11/49... Loss: 0.01096213... Valid Loss: 0.01096473...\n",
      "Epoch: 25/40... Step: 21/49... Loss: 0.01048625... Valid Loss: 0.01073568...\n",
      "Epoch: 25/40... Step: 31/49... Loss: 0.01055718... Valid Loss: 0.01120222...\n",
      "Epoch: 25/40... Step: 41/49... Loss: 0.01085441... Valid Loss: 0.01103851...\n",
      "Epoch: 26/40... Step: 1/49... Loss: 0.01029442... Valid Loss: 0.01061230...\n",
      "Epoch: 26/40... Step: 11/49... Loss: 0.01047431... Valid Loss: 0.01071868...\n",
      "Epoch: 26/40... Step: 21/49... Loss: 0.01076864... Valid Loss: 0.01074156...\n",
      "Epoch: 26/40... Step: 31/49... Loss: 0.01042418... Valid Loss: 0.01045409...\n",
      "Valid loss decreased (0.010469-->0.010454). Saving model...\n",
      "Epoch: 26/40... Step: 41/49... Loss: 0.01041671... Valid Loss: 0.01072486...\n",
      "Epoch: 27/40... Step: 1/49... Loss: 0.01111769... Valid Loss: 0.01051793...\n",
      "Epoch: 27/40... Step: 11/49... Loss: 0.01012592... Valid Loss: 0.01092924...\n",
      "Epoch: 27/40... Step: 21/49... Loss: 0.01068788... Valid Loss: 0.01111149...\n",
      "Epoch: 27/40... Step: 31/49... Loss: 0.01048678... Valid Loss: 0.01052205...\n",
      "Epoch: 27/40... Step: 41/49... Loss: 0.01044450... Valid Loss: 0.01041837...\n",
      "Valid loss decreased (0.010454-->0.010418). Saving model...\n",
      "Epoch: 28/40... Step: 1/49... Loss: 0.01051493... Valid Loss: 0.01068249...\n",
      "Epoch: 28/40... Step: 11/49... Loss: 0.01056015... Valid Loss: 0.01051612...\n",
      "Epoch: 28/40... Step: 21/49... Loss: 0.00988178... Valid Loss: 0.01083584...\n",
      "Epoch: 28/40... Step: 31/49... Loss: 0.01041340... Valid Loss: 0.01050552...\n",
      "Epoch: 28/40... Step: 41/49... Loss: 0.01055323... Valid Loss: 0.01058090...\n",
      "Epoch: 29/40... Step: 1/49... Loss: 0.01101322... Valid Loss: 0.01159502...\n",
      "Epoch: 29/40... Step: 11/49... Loss: 0.01097131... Valid Loss: 0.01079990...\n",
      "Epoch: 29/40... Step: 21/49... Loss: 0.01060396... Valid Loss: 0.01046556...\n",
      "Epoch: 29/40... Step: 31/49... Loss: 0.01042069... Valid Loss: 0.01085992...\n",
      "Epoch: 29/40... Step: 41/49... Loss: 0.01076044... Valid Loss: 0.01059651...\n",
      "Epoch: 30/40... Step: 1/49... Loss: 0.01067759... Valid Loss: 0.01059992...\n",
      "Epoch: 30/40... Step: 11/49... Loss: 0.01024822... Valid Loss: 0.01071838...\n",
      "Epoch: 30/40... Step: 21/49... Loss: 0.01104032... Valid Loss: 0.01054116...\n",
      "Epoch: 30/40... Step: 31/49... Loss: 0.00988123... Valid Loss: 0.01083005...\n",
      "Epoch: 30/40... Step: 41/49... Loss: 0.00990892... Valid Loss: 0.01043832...\n",
      "Epoch: 31/40... Step: 1/49... Loss: 0.01092125... Valid Loss: 0.01086944...\n",
      "Epoch: 31/40... Step: 11/49... Loss: 0.01008936... Valid Loss: 0.01057581...\n",
      "Epoch: 31/40... Step: 21/49... Loss: 0.01114045... Valid Loss: 0.01158499...\n",
      "Epoch: 31/40... Step: 31/49... Loss: 0.01089237... Valid Loss: 0.01052540...\n",
      "Epoch: 31/40... Step: 41/49... Loss: 0.01081824... Valid Loss: 0.01059107...\n",
      "Epoch: 32/40... Step: 1/49... Loss: 0.01079467... Valid Loss: 0.01086061...\n",
      "Epoch: 32/40... Step: 11/49... Loss: 0.01021416... Valid Loss: 0.01096337...\n",
      "Epoch: 32/40... Step: 21/49... Loss: 0.01124643... Valid Loss: 0.01070135...\n",
      "Epoch: 32/40... Step: 31/49... Loss: 0.01159195... Valid Loss: 0.01135090...\n",
      "Epoch: 32/40... Step: 41/49... Loss: 0.01078481... Valid Loss: 0.01141362...\n",
      "Epoch: 33/40... Step: 1/49... Loss: 0.01070262... Valid Loss: 0.01085452...\n",
      "Epoch: 33/40... Step: 11/49... Loss: 0.01144706... Valid Loss: 0.01044175...\n",
      "Epoch: 33/40... Step: 21/49... Loss: 0.01070594... Valid Loss: 0.01057493...\n",
      "Epoch: 33/40... Step: 31/49... Loss: 0.01051871... Valid Loss: 0.01063167...\n",
      "Epoch: 33/40... Step: 41/49... Loss: 0.01031444... Valid Loss: 0.01063405...\n",
      "Epoch: 34/40... Step: 1/49... Loss: 0.01033868... Valid Loss: 0.01087930...\n",
      "Epoch: 34/40... Step: 11/49... Loss: 0.01091867... Valid Loss: 0.01072713...\n",
      "Epoch: 34/40... Step: 21/49... Loss: 0.01078831... Valid Loss: 0.01068527...\n",
      "Epoch: 34/40... Step: 31/49... Loss: 0.01057538... Valid Loss: 0.01088224...\n",
      "Epoch: 34/40... Step: 41/49... Loss: 0.01161169... Valid Loss: 0.01106166...\n",
      "Epoch: 35/40... Step: 1/49... Loss: 0.01072473... Valid Loss: 0.01050204...\n",
      "Epoch: 35/40... Step: 11/49... Loss: 0.01066388... Valid Loss: 0.01045353...\n",
      "Epoch: 35/40... Step: 21/49... Loss: 0.00987125... Valid Loss: 0.01101006...\n",
      "Epoch: 35/40... Step: 31/49... Loss: 0.01070412... Valid Loss: 0.01054607...\n",
      "Epoch: 35/40... Step: 41/49... Loss: 0.01096641... Valid Loss: 0.01047969...\n",
      "Epoch: 36/40... Step: 1/49... Loss: 0.01109770... Valid Loss: 0.01074819...\n",
      "Epoch: 36/40... Step: 11/49... Loss: 0.00998908... Valid Loss: 0.01040381...\n",
      "Valid loss decreased (0.010418-->0.010404). Saving model...\n",
      "Epoch: 36/40... Step: 21/49... Loss: 0.01091078... Valid Loss: 0.01040105...\n",
      "Valid loss decreased (0.010404-->0.010401). Saving model...\n",
      "Epoch: 36/40... Step: 31/49... Loss: 0.01061081... Valid Loss: 0.01064949...\n",
      "Epoch: 36/40... Step: 41/49... Loss: 0.00997853... Valid Loss: 0.01052916...\n",
      "Epoch: 37/40... Step: 1/49... Loss: 0.01086088... Valid Loss: 0.01057519...\n",
      "Epoch: 37/40... Step: 11/49... Loss: 0.01032346... Valid Loss: 0.01072425...\n",
      "Epoch: 37/40... Step: 21/49... Loss: 0.01069856... Valid Loss: 0.01049155...\n",
      "Epoch: 37/40... Step: 31/49... Loss: 0.01111298... Valid Loss: 0.01066905...\n",
      "Epoch: 37/40... Step: 41/49... Loss: 0.01158384... Valid Loss: 0.01059351...\n",
      "Epoch: 38/40... Step: 1/49... Loss: 0.01015420... Valid Loss: 0.01051742...\n",
      "Epoch: 38/40... Step: 11/49... Loss: 0.01074086... Valid Loss: 0.01042665...\n",
      "Epoch: 38/40... Step: 21/49... Loss: 0.01018363... Valid Loss: 0.01046381...\n",
      "Epoch: 38/40... Step: 31/49... Loss: 0.01078947... Valid Loss: 0.01063270...\n",
      "Epoch: 38/40... Step: 41/49... Loss: 0.01107929... Valid Loss: 0.01059756...\n",
      "Epoch: 39/40... Step: 1/49... Loss: 0.01027753... Valid Loss: 0.01052953...\n",
      "Epoch: 39/40... Step: 11/49... Loss: 0.01124873... Valid Loss: 0.01098614...\n",
      "Epoch: 39/40... Step: 21/49... Loss: 0.01125203... Valid Loss: 0.01056143...\n",
      "Epoch: 39/40... Step: 31/49... Loss: 0.01078834... Valid Loss: 0.01061895...\n",
      "Epoch: 39/40... Step: 41/49... Loss: 0.01043348... Valid Loss: 0.01056882...\n",
      "Epoch: 40/40... Step: 1/49... Loss: 0.01102317... Valid Loss: 0.01046410...\n",
      "Epoch: 40/40... Step: 11/49... Loss: 0.00983809... Valid Loss: 0.01056084...\n",
      "Epoch: 40/40... Step: 21/49... Loss: 0.01057863... Valid Loss: 0.01043485...\n",
      "Epoch: 40/40... Step: 31/49... Loss: 0.01067940... Valid Loss: 0.01043359...\n",
      "Epoch: 40/40... Step: 41/49... Loss: 0.01012399... Valid Loss: 0.01077973...\n",
      "train dataset 2\n",
      "Epoch: 1/40... Step: 1/49... Loss: 0.01113029... Valid Loss: 0.01066137...\n",
      "Epoch: 1/40... Step: 11/49... Loss: 0.01097652... Valid Loss: 0.01104444...\n",
      "Epoch: 1/40... Step: 21/49... Loss: 0.01047026... Valid Loss: 0.01088057...\n",
      "Epoch: 1/40... Step: 31/49... Loss: 0.01011972... Valid Loss: 0.01078043...\n",
      "Epoch: 1/40... Step: 41/49... Loss: 0.01098442... Valid Loss: 0.01080317...\n",
      "Epoch: 2/40... Step: 1/49... Loss: 0.01050134... Valid Loss: 0.01080723...\n",
      "Epoch: 2/40... Step: 11/49... Loss: 0.01057967... Valid Loss: 0.01076880...\n",
      "Epoch: 2/40... Step: 21/49... Loss: 0.01091154... Valid Loss: 0.01108097...\n",
      "Epoch: 2/40... Step: 31/49... Loss: 0.01130268... Valid Loss: 0.01143344...\n",
      "Epoch: 2/40... Step: 41/49... Loss: 0.01065427... Valid Loss: 0.01107130...\n",
      "Epoch: 3/40... Step: 1/49... Loss: 0.01065856... Valid Loss: 0.01089093...\n",
      "Epoch: 3/40... Step: 11/49... Loss: 0.01089325... Valid Loss: 0.01140727...\n",
      "Epoch: 3/40... Step: 21/49... Loss: 0.01177320... Valid Loss: 0.01183579...\n",
      "Epoch: 3/40... Step: 31/49... Loss: 0.01111741... Valid Loss: 0.01063783...\n",
      "Epoch: 3/40... Step: 41/49... Loss: 0.01041668... Valid Loss: 0.01126701...\n",
      "Epoch: 4/40... Step: 1/49... Loss: 0.01014261... Valid Loss: 0.01075717...\n",
      "Epoch: 4/40... Step: 11/49... Loss: 0.01065191... Valid Loss: 0.01075609...\n",
      "Epoch: 4/40... Step: 21/49... Loss: 0.01100851... Valid Loss: 0.01137269...\n",
      "Epoch: 4/40... Step: 31/49... Loss: 0.01148205... Valid Loss: 0.01064315...\n",
      "Epoch: 4/40... Step: 41/49... Loss: 0.01010585... Valid Loss: 0.01093971...\n",
      "Epoch: 5/40... Step: 1/49... Loss: 0.00973676... Valid Loss: 0.01093744...\n",
      "Epoch: 5/40... Step: 11/49... Loss: 0.01030554... Valid Loss: 0.01129228...\n",
      "Epoch: 5/40... Step: 21/49... Loss: 0.01094021... Valid Loss: 0.01097465...\n",
      "Epoch: 5/40... Step: 31/49... Loss: 0.00958731... Valid Loss: 0.01062822...\n",
      "Epoch: 5/40... Step: 41/49... Loss: 0.01076751... Valid Loss: 0.01077256...\n",
      "Epoch: 6/40... Step: 1/49... Loss: 0.01036464... Valid Loss: 0.01058835...\n",
      "Epoch: 6/40... Step: 11/49... Loss: 0.01179832... Valid Loss: 0.01107158...\n",
      "Epoch: 6/40... Step: 21/49... Loss: 0.01136279... Valid Loss: 0.01064453...\n",
      "Epoch: 6/40... Step: 31/49... Loss: 0.01119776... Valid Loss: 0.01077950...\n",
      "Epoch: 6/40... Step: 41/49... Loss: 0.00999837... Valid Loss: 0.01103123...\n",
      "Epoch: 7/40... Step: 1/49... Loss: 0.01024025... Valid Loss: 0.01060582...\n",
      "Epoch: 7/40... Step: 11/49... Loss: 0.01066361... Valid Loss: 0.01054744...\n",
      "Epoch: 7/40... Step: 21/49... Loss: 0.01055265... Valid Loss: 0.01091829...\n",
      "Epoch: 7/40... Step: 31/49... Loss: 0.01058203... Valid Loss: 0.01086670...\n",
      "Epoch: 7/40... Step: 41/49... Loss: 0.01068722... Valid Loss: 0.01069835...\n",
      "Epoch: 8/40... Step: 1/49... Loss: 0.01020784... Valid Loss: 0.01093187...\n",
      "Epoch: 8/40... Step: 11/49... Loss: 0.01072016... Valid Loss: 0.01128782...\n",
      "Epoch: 8/40... Step: 21/49... Loss: 0.01096988... Valid Loss: 0.01068411...\n",
      "Epoch: 8/40... Step: 31/49... Loss: 0.01068654... Valid Loss: 0.01079503...\n",
      "Epoch: 8/40... Step: 41/49... Loss: 0.00996860... Valid Loss: 0.01059164...\n",
      "Epoch: 9/40... Step: 1/49... Loss: 0.01011645... Valid Loss: 0.01069217...\n",
      "Epoch: 9/40... Step: 11/49... Loss: 0.01082783... Valid Loss: 0.01061169...\n",
      "Epoch: 9/40... Step: 21/49... Loss: 0.01090149... Valid Loss: 0.01091026...\n",
      "Epoch: 9/40... Step: 31/49... Loss: 0.01089865... Valid Loss: 0.01059740...\n",
      "Epoch: 9/40... Step: 41/49... Loss: 0.01071901... Valid Loss: 0.01099116...\n",
      "Epoch: 10/40... Step: 1/49... Loss: 0.01039166... Valid Loss: 0.01065522...\n",
      "Epoch: 10/40... Step: 11/49... Loss: 0.01052563... Valid Loss: 0.01086607...\n",
      "Epoch: 10/40... Step: 21/49... Loss: 0.01041189... Valid Loss: 0.01068635...\n",
      "Epoch: 10/40... Step: 31/49... Loss: 0.01129020... Valid Loss: 0.01130717...\n",
      "Epoch: 10/40... Step: 41/49... Loss: 0.01052873... Valid Loss: 0.01077206...\n",
      "Epoch: 11/40... Step: 1/49... Loss: 0.01094103... Valid Loss: 0.01072753...\n",
      "Epoch: 11/40... Step: 11/49... Loss: 0.01019308... Valid Loss: 0.01083647...\n",
      "Epoch: 11/40... Step: 21/49... Loss: 0.01089776... Valid Loss: 0.01060063...\n",
      "Epoch: 11/40... Step: 31/49... Loss: 0.01016271... Valid Loss: 0.01080949...\n",
      "Epoch: 11/40... Step: 41/49... Loss: 0.01035836... Valid Loss: 0.01067153...\n",
      "Epoch: 12/40... Step: 1/49... Loss: 0.01031215... Valid Loss: 0.01065421...\n",
      "Epoch: 12/40... Step: 11/49... Loss: 0.01053456... Valid Loss: 0.01054101...\n",
      "Epoch: 12/40... Step: 21/49... Loss: 0.01042419... Valid Loss: 0.01060408...\n",
      "Epoch: 12/40... Step: 31/49... Loss: 0.01160439... Valid Loss: 0.01118009...\n",
      "Epoch: 12/40... Step: 41/49... Loss: 0.01030279... Valid Loss: 0.01076093...\n",
      "Epoch: 13/40... Step: 1/49... Loss: 0.01069586... Valid Loss: 0.01107596...\n",
      "Epoch: 13/40... Step: 11/49... Loss: 0.01127505... Valid Loss: 0.01083802...\n",
      "Epoch: 13/40... Step: 21/49... Loss: 0.01087484... Valid Loss: 0.01087771...\n",
      "Epoch: 13/40... Step: 31/49... Loss: 0.01039723... Valid Loss: 0.01066751...\n",
      "Epoch: 13/40... Step: 41/49... Loss: 0.01049644... Valid Loss: 0.01086335...\n",
      "Epoch: 14/40... Step: 1/49... Loss: 0.01070490... Valid Loss: 0.01063970...\n",
      "Epoch: 14/40... Step: 11/49... Loss: 0.01014379... Valid Loss: 0.01065497...\n",
      "Epoch: 14/40... Step: 21/49... Loss: 0.01050016... Valid Loss: 0.01120551...\n",
      "Epoch: 14/40... Step: 31/49... Loss: 0.01059827... Valid Loss: 0.01163050...\n",
      "Epoch: 14/40... Step: 41/49... Loss: 0.01099344... Valid Loss: 0.01069314...\n",
      "Epoch: 15/40... Step: 1/49... Loss: 0.01074479... Valid Loss: 0.01083909...\n",
      "Epoch: 15/40... Step: 11/49... Loss: 0.01106687... Valid Loss: 0.01097637...\n",
      "Epoch: 15/40... Step: 21/49... Loss: 0.01074033... Valid Loss: 0.01083511...\n",
      "Epoch: 15/40... Step: 31/49... Loss: 0.00970452... Valid Loss: 0.01064423...\n",
      "Epoch: 15/40... Step: 41/49... Loss: 0.01054533... Valid Loss: 0.01058833...\n",
      "Epoch: 16/40... Step: 1/49... Loss: 0.01060432... Valid Loss: 0.01097582...\n",
      "Epoch: 16/40... Step: 11/49... Loss: 0.00989806... Valid Loss: 0.01070151...\n",
      "Epoch: 16/40... Step: 21/49... Loss: 0.01079438... Valid Loss: 0.01064146...\n",
      "Epoch: 16/40... Step: 31/49... Loss: 0.00999344... Valid Loss: 0.01082156...\n",
      "Epoch: 16/40... Step: 41/49... Loss: 0.01071469... Valid Loss: 0.01059736...\n",
      "Epoch: 17/40... Step: 1/49... Loss: 0.01030179... Valid Loss: 0.01063813...\n",
      "Epoch: 17/40... Step: 11/49... Loss: 0.01082197... Valid Loss: 0.01096800...\n",
      "Epoch: 17/40... Step: 21/49... Loss: 0.01118219... Valid Loss: 0.01110506...\n",
      "Epoch: 17/40... Step: 31/49... Loss: 0.01121357... Valid Loss: 0.01091120...\n",
      "Epoch: 17/40... Step: 41/49... Loss: 0.01069115... Valid Loss: 0.01073984...\n",
      "Epoch: 18/40... Step: 1/49... Loss: 0.01096375... Valid Loss: 0.01089055...\n",
      "Epoch: 18/40... Step: 11/49... Loss: 0.01112316... Valid Loss: 0.01073893...\n",
      "Epoch: 18/40... Step: 21/49... Loss: 0.01035378... Valid Loss: 0.01086391...\n",
      "Epoch: 18/40... Step: 31/49... Loss: 0.01061927... Valid Loss: 0.01091209...\n",
      "Epoch: 18/40... Step: 41/49... Loss: 0.01058158... Valid Loss: 0.01069825...\n",
      "Epoch: 19/40... Step: 1/49... Loss: 0.01087242... Valid Loss: 0.01063379...\n",
      "Epoch: 19/40... Step: 11/49... Loss: 0.01108111... Valid Loss: 0.01088271...\n",
      "Epoch: 19/40... Step: 21/49... Loss: 0.01078486... Valid Loss: 0.01104176...\n",
      "Epoch: 19/40... Step: 31/49... Loss: 0.01040665... Valid Loss: 0.01063800...\n",
      "Epoch: 19/40... Step: 41/49... Loss: 0.00999642... Valid Loss: 0.01078550...\n",
      "Epoch: 20/40... Step: 1/49... Loss: 0.01023386... Valid Loss: 0.01068177...\n",
      "Epoch: 20/40... Step: 11/49... Loss: 0.01061003... Valid Loss: 0.01078913...\n",
      "Epoch: 20/40... Step: 21/49... Loss: 0.01070597... Valid Loss: 0.01071649...\n",
      "Epoch: 20/40... Step: 31/49... Loss: 0.01050773... Valid Loss: 0.01058869...\n",
      "Epoch: 20/40... Step: 41/49... Loss: 0.01076687... Valid Loss: 0.01063025...\n",
      "Epoch: 21/40... Step: 1/49... Loss: 0.01061198... Valid Loss: 0.01127813...\n",
      "Epoch: 21/40... Step: 11/49... Loss: 0.01057742... Valid Loss: 0.01064017...\n",
      "Epoch: 21/40... Step: 21/49... Loss: 0.01091453... Valid Loss: 0.01060688...\n",
      "Epoch: 21/40... Step: 31/49... Loss: 0.01055236... Valid Loss: 0.01052330...\n",
      "Epoch: 21/40... Step: 41/49... Loss: 0.01080955... Valid Loss: 0.01079050...\n",
      "Epoch: 22/40... Step: 1/49... Loss: 0.01186720... Valid Loss: 0.01128972...\n",
      "Epoch: 22/40... Step: 11/49... Loss: 0.01066582... Valid Loss: 0.01065383...\n",
      "Epoch: 22/40... Step: 21/49... Loss: 0.01080186... Valid Loss: 0.01077092...\n",
      "Epoch: 22/40... Step: 31/49... Loss: 0.01031403... Valid Loss: 0.01082616...\n",
      "Epoch: 22/40... Step: 41/49... Loss: 0.00988869... Valid Loss: 0.01061793...\n",
      "Epoch: 23/40... Step: 1/49... Loss: 0.01072000... Valid Loss: 0.01069863...\n",
      "Epoch: 23/40... Step: 11/49... Loss: 0.01044296... Valid Loss: 0.01075155...\n",
      "Epoch: 23/40... Step: 21/49... Loss: 0.01013664... Valid Loss: 0.01067968...\n",
      "Epoch: 23/40... Step: 31/49... Loss: 0.01010630... Valid Loss: 0.01061554...\n",
      "Epoch: 23/40... Step: 41/49... Loss: 0.01073321... Valid Loss: 0.01113265...\n",
      "Epoch: 24/40... Step: 1/49... Loss: 0.01054356... Valid Loss: 0.01057110...\n",
      "Epoch: 24/40... Step: 11/49... Loss: 0.01054384... Valid Loss: 0.01072166...\n",
      "Epoch: 24/40... Step: 21/49... Loss: 0.00991704... Valid Loss: 0.01071395...\n",
      "Epoch: 24/40... Step: 31/49... Loss: 0.00993291... Valid Loss: 0.01086671...\n",
      "Epoch: 24/40... Step: 41/49... Loss: 0.01145707... Valid Loss: 0.01206783...\n",
      "Epoch: 25/40... Step: 1/49... Loss: 0.01097077... Valid Loss: 0.01113549...\n",
      "Epoch: 25/40... Step: 11/49... Loss: 0.01021685... Valid Loss: 0.01109226...\n",
      "Epoch: 25/40... Step: 21/49... Loss: 0.01023204... Valid Loss: 0.01112498...\n",
      "Epoch: 25/40... Step: 31/49... Loss: 0.01003692... Valid Loss: 0.01055756...\n",
      "Epoch: 25/40... Step: 41/49... Loss: 0.01020915... Valid Loss: 0.01068595...\n",
      "Epoch: 26/40... Step: 1/49... Loss: 0.01144044... Valid Loss: 0.01060733...\n",
      "Epoch: 26/40... Step: 11/49... Loss: 0.01068548... Valid Loss: 0.01070200...\n",
      "Epoch: 26/40... Step: 21/49... Loss: 0.01037000... Valid Loss: 0.01078066...\n",
      "Epoch: 26/40... Step: 31/49... Loss: 0.01025842... Valid Loss: 0.01096301...\n",
      "Epoch: 26/40... Step: 41/49... Loss: 0.01023289... Valid Loss: 0.01101428...\n",
      "Epoch: 27/40... Step: 1/49... Loss: 0.01014795... Valid Loss: 0.01064777...\n",
      "Epoch: 27/40... Step: 11/49... Loss: 0.01038017... Valid Loss: 0.01062269...\n",
      "Epoch: 27/40... Step: 21/49... Loss: 0.01095633... Valid Loss: 0.01145998...\n",
      "Epoch: 27/40... Step: 31/49... Loss: 0.01025717... Valid Loss: 0.01074257...\n",
      "Epoch: 27/40... Step: 41/49... Loss: 0.01034143... Valid Loss: 0.01075336...\n",
      "Epoch: 28/40... Step: 1/49... Loss: 0.01087663... Valid Loss: 0.01055591...\n",
      "Epoch: 28/40... Step: 11/49... Loss: 0.01129077... Valid Loss: 0.01080249...\n",
      "Epoch: 28/40... Step: 21/49... Loss: 0.01021377... Valid Loss: 0.01088912...\n",
      "Epoch: 28/40... Step: 31/49... Loss: 0.01059720... Valid Loss: 0.01072751...\n",
      "Epoch: 28/40... Step: 41/49... Loss: 0.00997544... Valid Loss: 0.01069450...\n",
      "Epoch: 29/40... Step: 1/49... Loss: 0.01060100... Valid Loss: 0.01122595...\n",
      "Epoch: 29/40... Step: 11/49... Loss: 0.01073048... Valid Loss: 0.01123805...\n",
      "Epoch: 29/40... Step: 21/49... Loss: 0.01067711... Valid Loss: 0.01121871...\n",
      "Epoch: 29/40... Step: 31/49... Loss: 0.00994295... Valid Loss: 0.01097544...\n",
      "Epoch: 29/40... Step: 41/49... Loss: 0.01102863... Valid Loss: 0.01082416...\n",
      "Epoch: 30/40... Step: 1/49... Loss: 0.01040677... Valid Loss: 0.01058329...\n",
      "Epoch: 30/40... Step: 11/49... Loss: 0.01005785... Valid Loss: 0.01055210...\n",
      "Epoch: 30/40... Step: 21/49... Loss: 0.00983564... Valid Loss: 0.01080403...\n",
      "Epoch: 30/40... Step: 31/49... Loss: 0.01079896... Valid Loss: 0.01060820...\n",
      "Epoch: 30/40... Step: 41/49... Loss: 0.01029041... Valid Loss: 0.01096348...\n",
      "Epoch: 31/40... Step: 1/49... Loss: 0.01017444... Valid Loss: 0.01097124...\n",
      "Epoch: 31/40... Step: 11/49... Loss: 0.01010489... Valid Loss: 0.01084333...\n",
      "Epoch: 31/40... Step: 21/49... Loss: 0.01015367... Valid Loss: 0.01108397...\n",
      "Epoch: 31/40... Step: 31/49... Loss: 0.01109932... Valid Loss: 0.01119522...\n",
      "Epoch: 31/40... Step: 41/49... Loss: 0.01129443... Valid Loss: 0.01121415...\n",
      "Epoch: 32/40... Step: 1/49... Loss: 0.01042128... Valid Loss: 0.01081486...\n",
      "Epoch: 32/40... Step: 11/49... Loss: 0.01065248... Valid Loss: 0.01089860...\n",
      "Epoch: 32/40... Step: 21/49... Loss: 0.01049864... Valid Loss: 0.01062365...\n",
      "Epoch: 32/40... Step: 31/49... Loss: 0.01046656... Valid Loss: 0.01090118...\n",
      "Epoch: 32/40... Step: 41/49... Loss: 0.01039316... Valid Loss: 0.01070623...\n",
      "Epoch: 33/40... Step: 1/49... Loss: 0.01109958... Valid Loss: 0.01079768...\n",
      "Epoch: 33/40... Step: 11/49... Loss: 0.00995073... Valid Loss: 0.01093566...\n",
      "Epoch: 33/40... Step: 21/49... Loss: 0.01071773... Valid Loss: 0.01073041...\n",
      "Epoch: 33/40... Step: 31/49... Loss: 0.01055292... Valid Loss: 0.01081716...\n",
      "Epoch: 33/40... Step: 41/49... Loss: 0.01037728... Valid Loss: 0.01066977...\n",
      "Epoch: 34/40... Step: 1/49... Loss: 0.01005826... Valid Loss: 0.01071358...\n",
      "Epoch: 34/40... Step: 11/49... Loss: 0.01002271... Valid Loss: 0.01086828...\n",
      "Epoch: 34/40... Step: 21/49... Loss: 0.01042180... Valid Loss: 0.01107947...\n",
      "Epoch: 34/40... Step: 31/49... Loss: 0.01061306... Valid Loss: 0.01070184...\n",
      "Epoch: 34/40... Step: 41/49... Loss: 0.01010097... Valid Loss: 0.01058137...\n",
      "Epoch: 35/40... Step: 1/49... Loss: 0.01054664... Valid Loss: 0.01068605...\n",
      "Epoch: 35/40... Step: 11/49... Loss: 0.01029558... Valid Loss: 0.01051234...\n",
      "Epoch: 35/40... Step: 21/49... Loss: 0.01069460... Valid Loss: 0.01070163...\n",
      "Epoch: 35/40... Step: 31/49... Loss: 0.01088927... Valid Loss: 0.01098554...\n",
      "Epoch: 35/40... Step: 41/49... Loss: 0.01041230... Valid Loss: 0.01094657...\n",
      "Epoch: 36/40... Step: 1/49... Loss: 0.01086380... Valid Loss: 0.01153429...\n",
      "Epoch: 36/40... Step: 11/49... Loss: 0.01067106... Valid Loss: 0.01127306...\n",
      "Epoch: 36/40... Step: 21/49... Loss: 0.01112716... Valid Loss: 0.01119263...\n",
      "Epoch: 36/40... Step: 31/49... Loss: 0.01000314... Valid Loss: 0.01064097...\n",
      "Epoch: 36/40... Step: 41/49... Loss: 0.01070427... Valid Loss: 0.01054403...\n",
      "Epoch: 37/40... Step: 1/49... Loss: 0.01002552... Valid Loss: 0.01066034...\n",
      "Epoch: 37/40... Step: 11/49... Loss: 0.01063348... Valid Loss: 0.01073083...\n",
      "Epoch: 37/40... Step: 21/49... Loss: 0.00962606... Valid Loss: 0.01053378...\n",
      "Epoch: 37/40... Step: 31/49... Loss: 0.01082550... Valid Loss: 0.01059372...\n",
      "Epoch: 37/40... Step: 41/49... Loss: 0.01019276... Valid Loss: 0.01066830...\n",
      "Epoch: 38/40... Step: 1/49... Loss: 0.01153505... Valid Loss: 0.01081536...\n",
      "Epoch: 38/40... Step: 11/49... Loss: 0.01029926... Valid Loss: 0.01077353...\n",
      "Epoch: 38/40... Step: 21/49... Loss: 0.01006057... Valid Loss: 0.01078203...\n",
      "Epoch: 38/40... Step: 31/49... Loss: 0.01058641... Valid Loss: 0.01080896...\n",
      "Epoch: 38/40... Step: 41/49... Loss: 0.01165050... Valid Loss: 0.01099103...\n",
      "Epoch: 39/40... Step: 1/49... Loss: 0.01005188... Valid Loss: 0.01064293...\n",
      "Epoch: 39/40... Step: 11/49... Loss: 0.01139519... Valid Loss: 0.01085264...\n",
      "Epoch: 39/40... Step: 21/49... Loss: 0.01055531... Valid Loss: 0.01061697...\n",
      "Epoch: 39/40... Step: 31/49... Loss: 0.01113358... Valid Loss: 0.01092076...\n",
      "Epoch: 39/40... Step: 41/49... Loss: 0.01012426... Valid Loss: 0.01069464...\n",
      "Epoch: 40/40... Step: 1/49... Loss: 0.01039702... Valid Loss: 0.01061291...\n",
      "Epoch: 40/40... Step: 11/49... Loss: 0.01071359... Valid Loss: 0.01056777...\n",
      "Epoch: 40/40... Step: 21/49... Loss: 0.01017359... Valid Loss: 0.01059121...\n",
      "Epoch: 40/40... Step: 31/49... Loss: 0.01095249... Valid Loss: 0.01054953...\n",
      "Epoch: 40/40... Step: 41/49... Loss: 0.01037436... Valid Loss: 0.01063954...\n",
      "train dataset 3\n",
      "Epoch: 1/40... Step: 1/49... Loss: 0.01079198... Valid Loss: 0.01023951...\n",
      "Valid loss decreased (0.010401-->0.010240). Saving model...\n",
      "Epoch: 1/40... Step: 11/49... Loss: 0.01046360... Valid Loss: 0.01036481...\n",
      "Epoch: 1/40... Step: 21/49... Loss: 0.01206468... Valid Loss: 0.01082429...\n",
      "Epoch: 1/40... Step: 31/49... Loss: 0.01171366... Valid Loss: 0.01126714...\n",
      "Epoch: 1/40... Step: 41/49... Loss: 0.01059254... Valid Loss: 0.01058836...\n",
      "Epoch: 2/40... Step: 1/49... Loss: 0.01090517... Valid Loss: 0.01052912...\n",
      "Epoch: 2/40... Step: 11/49... Loss: 0.01099638... Valid Loss: 0.01071154...\n",
      "Epoch: 2/40... Step: 21/49... Loss: 0.01057603... Valid Loss: 0.01080403...\n",
      "Epoch: 2/40... Step: 31/49... Loss: 0.01053103... Valid Loss: 0.01080098...\n",
      "Epoch: 2/40... Step: 41/49... Loss: 0.01063724... Valid Loss: 0.01048341...\n",
      "Epoch: 3/40... Step: 1/49... Loss: 0.01041074... Valid Loss: 0.01026938...\n",
      "Epoch: 3/40... Step: 11/49... Loss: 0.01022223... Valid Loss: 0.01029538...\n",
      "Epoch: 3/40... Step: 21/49... Loss: 0.01028323... Valid Loss: 0.01025977...\n",
      "Epoch: 3/40... Step: 31/49... Loss: 0.01071934... Valid Loss: 0.01047568...\n",
      "Epoch: 3/40... Step: 41/49... Loss: 0.01029650... Valid Loss: 0.01046470...\n",
      "Epoch: 4/40... Step: 1/49... Loss: 0.01022911... Valid Loss: 0.01062941...\n",
      "Epoch: 4/40... Step: 11/49... Loss: 0.01121616... Valid Loss: 0.01051467...\n",
      "Epoch: 4/40... Step: 21/49... Loss: 0.00985008... Valid Loss: 0.01030922...\n",
      "Epoch: 4/40... Step: 31/49... Loss: 0.01070058... Valid Loss: 0.01032643...\n",
      "Epoch: 4/40... Step: 41/49... Loss: 0.00989946... Valid Loss: 0.01031668...\n",
      "Epoch: 5/40... Step: 1/49... Loss: 0.01018431... Valid Loss: 0.01049946...\n",
      "Epoch: 5/40... Step: 11/49... Loss: 0.01081081... Valid Loss: 0.01060683...\n",
      "Epoch: 5/40... Step: 21/49... Loss: 0.00997510... Valid Loss: 0.01066881...\n",
      "Epoch: 5/40... Step: 31/49... Loss: 0.01046725... Valid Loss: 0.01070698...\n",
      "Epoch: 5/40... Step: 41/49... Loss: 0.01034103... Valid Loss: 0.01047765...\n",
      "Epoch: 6/40... Step: 1/49... Loss: 0.01008220... Valid Loss: 0.01039314...\n",
      "Epoch: 6/40... Step: 11/49... Loss: 0.01058253... Valid Loss: 0.01053201...\n",
      "Epoch: 6/40... Step: 21/49... Loss: 0.01023362... Valid Loss: 0.01060179...\n",
      "Epoch: 6/40... Step: 31/49... Loss: 0.01089234... Valid Loss: 0.01160987...\n",
      "Epoch: 6/40... Step: 41/49... Loss: 0.01059265... Valid Loss: 0.01062649...\n",
      "Epoch: 7/40... Step: 1/49... Loss: 0.00979460... Valid Loss: 0.01027018...\n",
      "Epoch: 7/40... Step: 11/49... Loss: 0.01034321... Valid Loss: 0.01024532...\n",
      "Epoch: 7/40... Step: 21/49... Loss: 0.01046613... Valid Loss: 0.01021728...\n",
      "Valid loss decreased (0.010240-->0.010217). Saving model...\n",
      "Epoch: 7/40... Step: 31/49... Loss: 0.01098395... Valid Loss: 0.01059769...\n",
      "Epoch: 7/40... Step: 41/49... Loss: 0.01041213... Valid Loss: 0.01063648...\n",
      "Epoch: 8/40... Step: 1/49... Loss: 0.01053045... Valid Loss: 0.01028405...\n",
      "Epoch: 8/40... Step: 11/49... Loss: 0.01032044... Valid Loss: 0.01063486...\n",
      "Epoch: 8/40... Step: 21/49... Loss: 0.01050048... Valid Loss: 0.01059405...\n",
      "Epoch: 8/40... Step: 31/49... Loss: 0.01110394... Valid Loss: 0.01126765...\n",
      "Epoch: 8/40... Step: 41/49... Loss: 0.01049491... Valid Loss: 0.01050641...\n",
      "Epoch: 9/40... Step: 1/49... Loss: 0.01026486... Valid Loss: 0.01021644...\n",
      "Valid loss decreased (0.010217-->0.010216). Saving model...\n",
      "Epoch: 9/40... Step: 11/49... Loss: 0.01039490... Valid Loss: 0.01038232...\n",
      "Epoch: 9/40... Step: 21/49... Loss: 0.00962869... Valid Loss: 0.01065611...\n",
      "Epoch: 9/40... Step: 31/49... Loss: 0.01104537... Valid Loss: 0.01110960...\n",
      "Epoch: 9/40... Step: 41/49... Loss: 0.01102219... Valid Loss: 0.01069432...\n",
      "Epoch: 10/40... Step: 1/49... Loss: 0.01053618... Valid Loss: 0.01061926...\n",
      "Epoch: 10/40... Step: 11/49... Loss: 0.01086678... Valid Loss: 0.01054369...\n",
      "Epoch: 10/40... Step: 21/49... Loss: 0.01119244... Valid Loss: 0.01030794...\n",
      "Epoch: 10/40... Step: 31/49... Loss: 0.00979377... Valid Loss: 0.01041297...\n",
      "Epoch: 10/40... Step: 41/49... Loss: 0.01117793... Valid Loss: 0.01029322...\n",
      "Epoch: 11/40... Step: 1/49... Loss: 0.01055793... Valid Loss: 0.01029032...\n",
      "Epoch: 11/40... Step: 11/49... Loss: 0.01022960... Valid Loss: 0.01032421...\n",
      "Epoch: 11/40... Step: 21/49... Loss: 0.01025033... Valid Loss: 0.01023057...\n",
      "Epoch: 11/40... Step: 31/49... Loss: 0.01056447... Valid Loss: 0.01032039...\n",
      "Epoch: 11/40... Step: 41/49... Loss: 0.01052603... Valid Loss: 0.01024319...\n",
      "Epoch: 12/40... Step: 1/49... Loss: 0.01013269... Valid Loss: 0.01026364...\n",
      "Epoch: 12/40... Step: 11/49... Loss: 0.01078450... Valid Loss: 0.01044244...\n",
      "Epoch: 12/40... Step: 21/49... Loss: 0.01047575... Valid Loss: 0.01046615...\n",
      "Epoch: 12/40... Step: 31/49... Loss: 0.01047010... Valid Loss: 0.01032396...\n",
      "Epoch: 12/40... Step: 41/49... Loss: 0.01067450... Valid Loss: 0.01051442...\n",
      "Epoch: 13/40... Step: 1/49... Loss: 0.01069633... Valid Loss: 0.01018885...\n",
      "Valid loss decreased (0.010216-->0.010189). Saving model...\n",
      "Epoch: 13/40... Step: 11/49... Loss: 0.01060041... Valid Loss: 0.01034386...\n",
      "Epoch: 13/40... Step: 21/49... Loss: 0.01094549... Valid Loss: 0.01104434...\n",
      "Epoch: 13/40... Step: 31/49... Loss: 0.01140136... Valid Loss: 0.01074502...\n",
      "Epoch: 13/40... Step: 41/49... Loss: 0.00987877... Valid Loss: 0.01047098...\n",
      "Epoch: 14/40... Step: 1/49... Loss: 0.01042562... Valid Loss: 0.01043822...\n",
      "Epoch: 14/40... Step: 11/49... Loss: 0.01051372... Valid Loss: 0.01027831...\n",
      "Epoch: 14/40... Step: 21/49... Loss: 0.01036036... Valid Loss: 0.01019382...\n",
      "Epoch: 14/40... Step: 31/49... Loss: 0.01044060... Valid Loss: 0.01040386...\n",
      "Epoch: 14/40... Step: 41/49... Loss: 0.01054702... Valid Loss: 0.01052166...\n",
      "Epoch: 15/40... Step: 1/49... Loss: 0.01062329... Valid Loss: 0.01028788...\n",
      "Epoch: 15/40... Step: 11/49... Loss: 0.01060891... Valid Loss: 0.01026904...\n",
      "Epoch: 15/40... Step: 21/49... Loss: 0.01034907... Valid Loss: 0.01021785...\n",
      "Epoch: 15/40... Step: 31/49... Loss: 0.01101828... Valid Loss: 0.01061798...\n",
      "Epoch: 15/40... Step: 41/49... Loss: 0.01033864... Valid Loss: 0.01027211...\n",
      "Epoch: 16/40... Step: 1/49... Loss: 0.01050470... Valid Loss: 0.01049549...\n",
      "Epoch: 16/40... Step: 11/49... Loss: 0.01041160... Valid Loss: 0.01022975...\n",
      "Epoch: 16/40... Step: 21/49... Loss: 0.01022919... Valid Loss: 0.01043959...\n",
      "Epoch: 16/40... Step: 31/49... Loss: 0.01092159... Valid Loss: 0.01033778...\n",
      "Epoch: 16/40... Step: 41/49... Loss: 0.01057367... Valid Loss: 0.01018235...\n",
      "Valid loss decreased (0.010189-->0.010182). Saving model...\n",
      "Epoch: 17/40... Step: 1/49... Loss: 0.01102536... Valid Loss: 0.01079115...\n",
      "Epoch: 17/40... Step: 11/49... Loss: 0.01037300... Valid Loss: 0.01038750...\n",
      "Epoch: 17/40... Step: 21/49... Loss: 0.01080492... Valid Loss: 0.01030885...\n",
      "Epoch: 17/40... Step: 31/49... Loss: 0.01009293... Valid Loss: 0.01023775...\n",
      "Epoch: 17/40... Step: 41/49... Loss: 0.01036990... Valid Loss: 0.01037260...\n",
      "Epoch: 18/40... Step: 1/49... Loss: 0.01136821... Valid Loss: 0.01121853...\n",
      "Epoch: 18/40... Step: 11/49... Loss: 0.01102247... Valid Loss: 0.01103850...\n",
      "Epoch: 18/40... Step: 21/49... Loss: 0.01121277... Valid Loss: 0.01130235...\n",
      "Epoch: 18/40... Step: 31/49... Loss: 0.01074267... Valid Loss: 0.01126324...\n",
      "Epoch: 18/40... Step: 41/49... Loss: 0.01083516... Valid Loss: 0.01038962...\n",
      "Epoch: 19/40... Step: 1/49... Loss: 0.01018601... Valid Loss: 0.01041296...\n",
      "Epoch: 19/40... Step: 11/49... Loss: 0.00999111... Valid Loss: 0.01023193...\n",
      "Epoch: 19/40... Step: 21/49... Loss: 0.00982210... Valid Loss: 0.01029600...\n",
      "Epoch: 19/40... Step: 31/49... Loss: 0.01035747... Valid Loss: 0.01023669...\n",
      "Epoch: 19/40... Step: 41/49... Loss: 0.01040628... Valid Loss: 0.01042097...\n",
      "Epoch: 20/40... Step: 1/49... Loss: 0.01074572... Valid Loss: 0.01037750...\n",
      "Epoch: 20/40... Step: 11/49... Loss: 0.01050423... Valid Loss: 0.01028352...\n",
      "Epoch: 20/40... Step: 21/49... Loss: 0.01138488... Valid Loss: 0.01047699...\n",
      "Epoch: 20/40... Step: 31/49... Loss: 0.00962673... Valid Loss: 0.01023200...\n",
      "Epoch: 20/40... Step: 41/49... Loss: 0.01004704... Valid Loss: 0.01047658...\n",
      "Epoch: 21/40... Step: 1/49... Loss: 0.01048047... Valid Loss: 0.01036403...\n",
      "Epoch: 21/40... Step: 11/49... Loss: 0.01006363... Valid Loss: 0.01057870...\n",
      "Epoch: 21/40... Step: 21/49... Loss: 0.01100585... Valid Loss: 0.01037311...\n",
      "Epoch: 21/40... Step: 31/49... Loss: 0.01082475... Valid Loss: 0.01036041...\n",
      "Epoch: 21/40... Step: 41/49... Loss: 0.01051068... Valid Loss: 0.01045693...\n",
      "Epoch: 22/40... Step: 1/49... Loss: 0.01007676... Valid Loss: 0.01029781...\n",
      "Epoch: 22/40... Step: 11/49... Loss: 0.01022740... Valid Loss: 0.01034920...\n",
      "Epoch: 22/40... Step: 21/49... Loss: 0.00979657... Valid Loss: 0.01029140...\n",
      "Epoch: 22/40... Step: 31/49... Loss: 0.00996469... Valid Loss: 0.01034488...\n",
      "Epoch: 22/40... Step: 41/49... Loss: 0.01056741... Valid Loss: 0.01023249...\n",
      "Epoch: 23/40... Step: 1/49... Loss: 0.01148899... Valid Loss: 0.01089910...\n",
      "Epoch: 23/40... Step: 11/49... Loss: 0.01104310... Valid Loss: 0.01059878...\n",
      "Epoch: 23/40... Step: 21/49... Loss: 0.01069842... Valid Loss: 0.01069339...\n",
      "Epoch: 23/40... Step: 31/49... Loss: 0.01037485... Valid Loss: 0.01069256...\n",
      "Epoch: 23/40... Step: 41/49... Loss: 0.01061598... Valid Loss: 0.01043641...\n",
      "Epoch: 24/40... Step: 1/49... Loss: 0.01061930... Valid Loss: 0.01030039...\n",
      "Epoch: 24/40... Step: 11/49... Loss: 0.01077901... Valid Loss: 0.01079737...\n",
      "Epoch: 24/40... Step: 21/49... Loss: 0.01003133... Valid Loss: 0.01070080...\n",
      "Epoch: 24/40... Step: 31/49... Loss: 0.01039559... Valid Loss: 0.01088526...\n",
      "Epoch: 24/40... Step: 41/49... Loss: 0.01028318... Valid Loss: 0.01078167...\n",
      "Epoch: 25/40... Step: 1/49... Loss: 0.01071077... Valid Loss: 0.01138708...\n",
      "Epoch: 25/40... Step: 11/49... Loss: 0.01007361... Valid Loss: 0.01042673...\n",
      "Epoch: 25/40... Step: 21/49... Loss: 0.01079381... Valid Loss: 0.01084892...\n",
      "Epoch: 25/40... Step: 31/49... Loss: 0.01103433... Valid Loss: 0.01041825...\n",
      "Epoch: 25/40... Step: 41/49... Loss: 0.01060370... Valid Loss: 0.01027005...\n",
      "Epoch: 26/40... Step: 1/49... Loss: 0.00998121... Valid Loss: 0.01027568...\n",
      "Epoch: 26/40... Step: 11/49... Loss: 0.01086977... Valid Loss: 0.01025844...\n",
      "Epoch: 26/40... Step: 21/49... Loss: 0.00991356... Valid Loss: 0.01034533...\n",
      "Epoch: 26/40... Step: 31/49... Loss: 0.01047267... Valid Loss: 0.01038441...\n",
      "Epoch: 26/40... Step: 41/49... Loss: 0.01062878... Valid Loss: 0.01037274...\n",
      "Epoch: 27/40... Step: 1/49... Loss: 0.01026310... Valid Loss: 0.01023309...\n",
      "Epoch: 27/40... Step: 11/49... Loss: 0.01035504... Valid Loss: 0.01025977...\n",
      "Epoch: 27/40... Step: 21/49... Loss: 0.01007800... Valid Loss: 0.01041724...\n",
      "Epoch: 27/40... Step: 31/49... Loss: 0.01022094... Valid Loss: 0.01035614...\n",
      "Epoch: 27/40... Step: 41/49... Loss: 0.01105489... Valid Loss: 0.01043432...\n",
      "Epoch: 28/40... Step: 1/49... Loss: 0.01006367... Valid Loss: 0.01031345...\n",
      "Epoch: 28/40... Step: 11/49... Loss: 0.01063084... Valid Loss: 0.01032602...\n",
      "Epoch: 28/40... Step: 21/49... Loss: 0.01006404... Valid Loss: 0.01047100...\n",
      "Epoch: 28/40... Step: 31/49... Loss: 0.01110730... Valid Loss: 0.01034148...\n",
      "Epoch: 28/40... Step: 41/49... Loss: 0.01072623... Valid Loss: 0.01019325...\n",
      "Epoch: 29/40... Step: 1/49... Loss: 0.01121136... Valid Loss: 0.01046229...\n",
      "Epoch: 29/40... Step: 11/49... Loss: 0.00983326... Valid Loss: 0.01026666...\n",
      "Epoch: 29/40... Step: 21/49... Loss: 0.01016839... Valid Loss: 0.01025269...\n",
      "Epoch: 29/40... Step: 31/49... Loss: 0.01036368... Valid Loss: 0.01021518...\n",
      "Epoch: 29/40... Step: 41/49... Loss: 0.01054274... Valid Loss: 0.01035456...\n",
      "Epoch: 30/40... Step: 1/49... Loss: 0.01058334... Valid Loss: 0.01041762...\n",
      "Epoch: 30/40... Step: 11/49... Loss: 0.01094032... Valid Loss: 0.01037557...\n",
      "Epoch: 30/40... Step: 21/49... Loss: 0.01083054... Valid Loss: 0.01025753...\n",
      "Epoch: 30/40... Step: 31/49... Loss: 0.01057994... Valid Loss: 0.01075266...\n",
      "Epoch: 30/40... Step: 41/49... Loss: 0.01096543... Valid Loss: 0.01019976...\n",
      "Epoch: 31/40... Step: 1/49... Loss: 0.01038171... Valid Loss: 0.01032697...\n",
      "Epoch: 31/40... Step: 11/49... Loss: 0.01008431... Valid Loss: 0.01030901...\n",
      "Epoch: 31/40... Step: 21/49... Loss: 0.01074732... Valid Loss: 0.01036224...\n",
      "Epoch: 31/40... Step: 31/49... Loss: 0.01061805... Valid Loss: 0.01044944...\n",
      "Epoch: 31/40... Step: 41/49... Loss: 0.01063504... Valid Loss: 0.01047710...\n",
      "Epoch: 32/40... Step: 1/49... Loss: 0.01071280... Valid Loss: 0.01023593...\n",
      "Epoch: 32/40... Step: 11/49... Loss: 0.01084358... Valid Loss: 0.01040642...\n",
      "Epoch: 32/40... Step: 21/49... Loss: 0.01125975... Valid Loss: 0.01115691...\n",
      "Epoch: 32/40... Step: 31/49... Loss: 0.01046463... Valid Loss: 0.01115876...\n",
      "Epoch: 32/40... Step: 41/49... Loss: 0.01089260... Valid Loss: 0.01067226...\n",
      "Epoch: 33/40... Step: 1/49... Loss: 0.01055231... Valid Loss: 0.01052413...\n",
      "Epoch: 33/40... Step: 11/49... Loss: 0.01002087... Valid Loss: 0.01027745...\n",
      "Epoch: 33/40... Step: 21/49... Loss: 0.01053418... Valid Loss: 0.01031176...\n",
      "Epoch: 33/40... Step: 31/49... Loss: 0.01124668... Valid Loss: 0.01044651...\n",
      "Epoch: 33/40... Step: 41/49... Loss: 0.01098779... Valid Loss: 0.01054112...\n",
      "Epoch: 34/40... Step: 1/49... Loss: 0.01024623... Valid Loss: 0.01026870...\n",
      "Epoch: 34/40... Step: 11/49... Loss: 0.01029254... Valid Loss: 0.01026721...\n",
      "Epoch: 34/40... Step: 21/49... Loss: 0.01118411... Valid Loss: 0.01052313...\n",
      "Epoch: 34/40... Step: 31/49... Loss: 0.00974850... Valid Loss: 0.01046918...\n",
      "Epoch: 34/40... Step: 41/49... Loss: 0.01016549... Valid Loss: 0.01024704...\n",
      "Epoch: 35/40... Step: 1/49... Loss: 0.01012488... Valid Loss: 0.01032227...\n",
      "Epoch: 35/40... Step: 11/49... Loss: 0.00968834... Valid Loss: 0.01039930...\n",
      "Epoch: 35/40... Step: 21/49... Loss: 0.01060816... Valid Loss: 0.01013347...\n",
      "Valid loss decreased (0.010182-->0.010133). Saving model...\n",
      "Epoch: 35/40... Step: 31/49... Loss: 0.01039143... Valid Loss: 0.01024874...\n",
      "Epoch: 35/40... Step: 41/49... Loss: 0.01047068... Valid Loss: 0.01038563...\n",
      "Epoch: 36/40... Step: 1/49... Loss: 0.01076502... Valid Loss: 0.01044331...\n",
      "Epoch: 36/40... Step: 11/49... Loss: 0.01022901... Valid Loss: 0.01037748...\n",
      "Epoch: 36/40... Step: 21/49... Loss: 0.01028105... Valid Loss: 0.01052747...\n",
      "Epoch: 36/40... Step: 31/49... Loss: 0.01016880... Valid Loss: 0.01028790...\n",
      "Epoch: 36/40... Step: 41/49... Loss: 0.01018426... Valid Loss: 0.01035303...\n",
      "Epoch: 37/40... Step: 1/49... Loss: 0.01079578... Valid Loss: 0.01081498...\n",
      "Epoch: 37/40... Step: 11/49... Loss: 0.01145802... Valid Loss: 0.01098561...\n",
      "Epoch: 37/40... Step: 21/49... Loss: 0.01124293... Valid Loss: 0.01026123...\n",
      "Epoch: 37/40... Step: 31/49... Loss: 0.01011845... Valid Loss: 0.01026488...\n",
      "Epoch: 37/40... Step: 41/49... Loss: 0.01023738... Valid Loss: 0.01027762...\n",
      "Epoch: 38/40... Step: 1/49... Loss: 0.01070664... Valid Loss: 0.01054017...\n",
      "Epoch: 38/40... Step: 11/49... Loss: 0.01115870... Valid Loss: 0.01034368...\n",
      "Epoch: 38/40... Step: 21/49... Loss: 0.00957706... Valid Loss: 0.01061707...\n",
      "Epoch: 38/40... Step: 31/49... Loss: 0.01092584... Valid Loss: 0.01017545...\n",
      "Epoch: 38/40... Step: 41/49... Loss: 0.01176636... Valid Loss: 0.01028394...\n",
      "Epoch: 39/40... Step: 1/49... Loss: 0.01011545... Valid Loss: 0.01032548...\n",
      "Epoch: 39/40... Step: 11/49... Loss: 0.01032327... Valid Loss: 0.01040745...\n",
      "Epoch: 39/40... Step: 21/49... Loss: 0.01076067... Valid Loss: 0.01028723...\n",
      "Epoch: 39/40... Step: 31/49... Loss: 0.01024690... Valid Loss: 0.01025061...\n",
      "Epoch: 39/40... Step: 41/49... Loss: 0.01022936... Valid Loss: 0.01029753...\n",
      "Epoch: 40/40... Step: 1/49... Loss: 0.00984327... Valid Loss: 0.01025835...\n",
      "Epoch: 40/40... Step: 11/49... Loss: 0.01054562... Valid Loss: 0.01024323...\n",
      "Epoch: 40/40... Step: 21/49... Loss: 0.01073060... Valid Loss: 0.01027445...\n",
      "Epoch: 40/40... Step: 31/49... Loss: 0.01041568... Valid Loss: 0.01055833...\n",
      "Epoch: 40/40... Step: 41/49... Loss: 0.01043140... Valid Loss: 0.01048982...\n",
      "train dataset 4\n",
      "Epoch: 1/40... Step: 1/49... Loss: 0.01051874... Valid Loss: 0.01102438...\n",
      "Epoch: 1/40... Step: 11/49... Loss: 0.01120905... Valid Loss: 0.01037790...\n",
      "Epoch: 1/40... Step: 21/49... Loss: 0.01075546... Valid Loss: 0.01041720...\n",
      "Epoch: 1/40... Step: 31/49... Loss: 0.01100301... Valid Loss: 0.01032830...\n",
      "Epoch: 1/40... Step: 41/49... Loss: 0.01037932... Valid Loss: 0.01072974...\n",
      "Epoch: 2/40... Step: 1/49... Loss: 0.01122912... Valid Loss: 0.01024570...\n",
      "Epoch: 2/40... Step: 11/49... Loss: 0.01123556... Valid Loss: 0.01081310...\n",
      "Epoch: 2/40... Step: 21/49... Loss: 0.01000988... Valid Loss: 0.01034699...\n",
      "Epoch: 2/40... Step: 31/49... Loss: 0.01028869... Valid Loss: 0.01049126...\n",
      "Epoch: 2/40... Step: 41/49... Loss: 0.01000597... Valid Loss: 0.01026700...\n",
      "Epoch: 3/40... Step: 1/49... Loss: 0.01067719... Valid Loss: 0.01040239...\n",
      "Epoch: 3/40... Step: 11/49... Loss: 0.01148607... Valid Loss: 0.01072632...\n",
      "Epoch: 3/40... Step: 21/49... Loss: 0.01078096... Valid Loss: 0.01027632...\n",
      "Epoch: 3/40... Step: 31/49... Loss: 0.01093243... Valid Loss: 0.01033546...\n",
      "Epoch: 3/40... Step: 41/49... Loss: 0.01084479... Valid Loss: 0.01083965...\n",
      "Epoch: 4/40... Step: 1/49... Loss: 0.01159509... Valid Loss: 0.01032785...\n",
      "Epoch: 4/40... Step: 11/49... Loss: 0.01076359... Valid Loss: 0.01031401...\n",
      "Epoch: 4/40... Step: 21/49... Loss: 0.01037235... Valid Loss: 0.01032969...\n",
      "Epoch: 4/40... Step: 31/49... Loss: 0.01060301... Valid Loss: 0.01036497...\n",
      "Epoch: 4/40... Step: 41/49... Loss: 0.01060510... Valid Loss: 0.01064581...\n",
      "Epoch: 5/40... Step: 1/49... Loss: 0.00973898... Valid Loss: 0.01039042...\n",
      "Epoch: 5/40... Step: 11/49... Loss: 0.01040227... Valid Loss: 0.01073873...\n",
      "Epoch: 5/40... Step: 21/49... Loss: 0.01070893... Valid Loss: 0.01034015...\n",
      "Epoch: 5/40... Step: 31/49... Loss: 0.01067061... Valid Loss: 0.01064298...\n",
      "Epoch: 5/40... Step: 41/49... Loss: 0.01063150... Valid Loss: 0.01043003...\n",
      "Epoch: 6/40... Step: 1/49... Loss: 0.01130898... Valid Loss: 0.01119809...\n",
      "Epoch: 6/40... Step: 11/49... Loss: 0.01089428... Valid Loss: 0.01045168...\n",
      "Epoch: 6/40... Step: 21/49... Loss: 0.01106085... Valid Loss: 0.01037791...\n",
      "Epoch: 6/40... Step: 31/49... Loss: 0.01085416... Valid Loss: 0.01043206...\n",
      "Epoch: 6/40... Step: 41/49... Loss: 0.01034021... Valid Loss: 0.01045588...\n",
      "Epoch: 7/40... Step: 1/49... Loss: 0.01079726... Valid Loss: 0.01072405...\n",
      "Epoch: 7/40... Step: 11/49... Loss: 0.01053192... Valid Loss: 0.01089070...\n",
      "Epoch: 7/40... Step: 21/49... Loss: 0.01032140... Valid Loss: 0.01046762...\n",
      "Epoch: 7/40... Step: 31/49... Loss: 0.01058986... Valid Loss: 0.01066429...\n",
      "Epoch: 7/40... Step: 41/49... Loss: 0.01007246... Valid Loss: 0.01097116...\n",
      "Epoch: 8/40... Step: 1/49... Loss: 0.01083327... Valid Loss: 0.01040845...\n",
      "Epoch: 8/40... Step: 11/49... Loss: 0.01050740... Valid Loss: 0.01030705...\n",
      "Epoch: 8/40... Step: 21/49... Loss: 0.01012369... Valid Loss: 0.01031998...\n",
      "Epoch: 8/40... Step: 31/49... Loss: 0.01104113... Valid Loss: 0.01041824...\n",
      "Epoch: 8/40... Step: 41/49... Loss: 0.00997153... Valid Loss: 0.01029863...\n",
      "Epoch: 9/40... Step: 1/49... Loss: 0.00983093... Valid Loss: 0.01029034...\n",
      "Epoch: 9/40... Step: 11/49... Loss: 0.01025416... Valid Loss: 0.01043636...\n",
      "Epoch: 9/40... Step: 21/49... Loss: 0.01064154... Valid Loss: 0.01049728...\n",
      "Epoch: 9/40... Step: 31/49... Loss: 0.01117155... Valid Loss: 0.01083128...\n",
      "Epoch: 9/40... Step: 41/49... Loss: 0.01021434... Valid Loss: 0.01029728...\n",
      "Epoch: 10/40... Step: 1/49... Loss: 0.01024339... Valid Loss: 0.01042039...\n",
      "Epoch: 10/40... Step: 11/49... Loss: 0.00994099... Valid Loss: 0.01050745...\n",
      "Epoch: 10/40... Step: 21/49... Loss: 0.01038030... Valid Loss: 0.01028841...\n",
      "Epoch: 10/40... Step: 31/49... Loss: 0.01074570... Valid Loss: 0.01051579...\n",
      "Epoch: 10/40... Step: 41/49... Loss: 0.01091954... Valid Loss: 0.01092816...\n",
      "Epoch: 11/40... Step: 1/49... Loss: 0.01086276... Valid Loss: 0.01080251...\n",
      "Epoch: 11/40... Step: 11/49... Loss: 0.01035503... Valid Loss: 0.01040055...\n",
      "Epoch: 11/40... Step: 21/49... Loss: 0.01064880... Valid Loss: 0.01079727...\n",
      "Epoch: 11/40... Step: 31/49... Loss: 0.01037792... Valid Loss: 0.01045188...\n",
      "Epoch: 11/40... Step: 41/49... Loss: 0.01036302... Valid Loss: 0.01059559...\n",
      "Epoch: 12/40... Step: 1/49... Loss: 0.01223584... Valid Loss: 0.01133910...\n",
      "Epoch: 12/40... Step: 11/49... Loss: 0.01075500... Valid Loss: 0.01040447...\n",
      "Epoch: 12/40... Step: 21/49... Loss: 0.01051695... Valid Loss: 0.01030404...\n",
      "Epoch: 12/40... Step: 31/49... Loss: 0.01012143... Valid Loss: 0.01027076...\n",
      "Epoch: 12/40... Step: 41/49... Loss: 0.01045191... Valid Loss: 0.01040758...\n",
      "Epoch: 13/40... Step: 1/49... Loss: 0.01064472... Valid Loss: 0.01032026...\n",
      "Epoch: 13/40... Step: 11/49... Loss: 0.01067049... Valid Loss: 0.01064775...\n",
      "Epoch: 13/40... Step: 21/49... Loss: 0.01081281... Valid Loss: 0.01033513...\n",
      "Epoch: 13/40... Step: 31/49... Loss: 0.01047405... Valid Loss: 0.01048829...\n",
      "Epoch: 13/40... Step: 41/49... Loss: 0.01065989... Valid Loss: 0.01034793...\n",
      "Epoch: 14/40... Step: 1/49... Loss: 0.01068992... Valid Loss: 0.01025181...\n",
      "Epoch: 14/40... Step: 11/49... Loss: 0.01058538... Valid Loss: 0.01046754...\n",
      "Epoch: 14/40... Step: 21/49... Loss: 0.01055637... Valid Loss: 0.01098871...\n",
      "Epoch: 14/40... Step: 31/49... Loss: 0.01084641... Valid Loss: 0.01106432...\n",
      "Epoch: 14/40... Step: 41/49... Loss: 0.01100104... Valid Loss: 0.01092054...\n",
      "Epoch: 15/40... Step: 1/49... Loss: 0.01068944... Valid Loss: 0.01088592...\n",
      "Epoch: 15/40... Step: 11/49... Loss: 0.01002622... Valid Loss: 0.01061247...\n",
      "Epoch: 15/40... Step: 21/49... Loss: 0.01063895... Valid Loss: 0.01029897...\n",
      "Epoch: 15/40... Step: 31/49... Loss: 0.01092769... Valid Loss: 0.01044476...\n",
      "Epoch: 15/40... Step: 41/49... Loss: 0.01009083... Valid Loss: 0.01056394...\n",
      "Epoch: 16/40... Step: 1/49... Loss: 0.01042636... Valid Loss: 0.01027017...\n",
      "Epoch: 16/40... Step: 11/49... Loss: 0.00998760... Valid Loss: 0.01029623...\n",
      "Epoch: 16/40... Step: 21/49... Loss: 0.01085655... Valid Loss: 0.01032812...\n",
      "Epoch: 16/40... Step: 31/49... Loss: 0.01013143... Valid Loss: 0.01031850...\n",
      "Epoch: 16/40... Step: 41/49... Loss: 0.01044474... Valid Loss: 0.01036986...\n",
      "Epoch: 17/40... Step: 1/49... Loss: 0.01072148... Valid Loss: 0.01042732...\n",
      "Epoch: 17/40... Step: 11/49... Loss: 0.01063858... Valid Loss: 0.01034002...\n",
      "Epoch: 17/40... Step: 21/49... Loss: 0.01052895... Valid Loss: 0.01051089...\n",
      "Epoch: 17/40... Step: 31/49... Loss: 0.01068973... Valid Loss: 0.01053232...\n",
      "Epoch: 17/40... Step: 41/49... Loss: 0.01077048... Valid Loss: 0.01061496...\n",
      "Epoch: 18/40... Step: 1/49... Loss: 0.01075937... Valid Loss: 0.01082714...\n",
      "Epoch: 18/40... Step: 11/49... Loss: 0.01046455... Valid Loss: 0.01045673...\n",
      "Epoch: 18/40... Step: 21/49... Loss: 0.00979640... Valid Loss: 0.01029944...\n",
      "Epoch: 18/40... Step: 31/49... Loss: 0.01149547... Valid Loss: 0.01089883...\n",
      "Epoch: 18/40... Step: 41/49... Loss: 0.00972921... Valid Loss: 0.01039665...\n",
      "Epoch: 19/40... Step: 1/49... Loss: 0.01002932... Valid Loss: 0.01027227...\n",
      "Epoch: 19/40... Step: 11/49... Loss: 0.01023534... Valid Loss: 0.01038863...\n",
      "Epoch: 19/40... Step: 21/49... Loss: 0.00996285... Valid Loss: 0.01062658...\n",
      "Epoch: 19/40... Step: 31/49... Loss: 0.01062284... Valid Loss: 0.01024680...\n",
      "Epoch: 19/40... Step: 41/49... Loss: 0.01016608... Valid Loss: 0.01045960...\n",
      "Epoch: 20/40... Step: 1/49... Loss: 0.01029105... Valid Loss: 0.01059568...\n",
      "Epoch: 20/40... Step: 11/49... Loss: 0.01011482... Valid Loss: 0.01041404...\n",
      "Epoch: 20/40... Step: 21/49... Loss: 0.01075423... Valid Loss: 0.01045628...\n",
      "Epoch: 20/40... Step: 31/49... Loss: 0.01040894... Valid Loss: 0.01046480...\n",
      "Epoch: 20/40... Step: 41/49... Loss: 0.01106071... Valid Loss: 0.01118551...\n",
      "Epoch: 21/40... Step: 1/49... Loss: 0.01082515... Valid Loss: 0.01044857...\n",
      "Epoch: 21/40... Step: 11/49... Loss: 0.01063701... Valid Loss: 0.01036447...\n",
      "Epoch: 21/40... Step: 21/49... Loss: 0.01036516... Valid Loss: 0.01105547...\n",
      "Epoch: 21/40... Step: 31/49... Loss: 0.01115571... Valid Loss: 0.01084166...\n",
      "Epoch: 21/40... Step: 41/49... Loss: 0.01002182... Valid Loss: 0.01032850...\n",
      "Epoch: 22/40... Step: 1/49... Loss: 0.01082028... Valid Loss: 0.01038171...\n",
      "Epoch: 22/40... Step: 11/49... Loss: 0.01061451... Valid Loss: 0.01028802...\n",
      "Epoch: 22/40... Step: 21/49... Loss: 0.01043400... Valid Loss: 0.01025365...\n",
      "Epoch: 22/40... Step: 31/49... Loss: 0.01029326... Valid Loss: 0.01041498...\n",
      "Epoch: 22/40... Step: 41/49... Loss: 0.01109123... Valid Loss: 0.01104601...\n",
      "Epoch: 23/40... Step: 1/49... Loss: 0.01076045... Valid Loss: 0.01057634...\n",
      "Epoch: 23/40... Step: 11/49... Loss: 0.01029169... Valid Loss: 0.01042401...\n",
      "Epoch: 23/40... Step: 21/49... Loss: 0.01036918... Valid Loss: 0.01037080...\n",
      "Epoch: 23/40... Step: 31/49... Loss: 0.01080260... Valid Loss: 0.01034246...\n",
      "Epoch: 23/40... Step: 41/49... Loss: 0.01012014... Valid Loss: 0.01045976...\n",
      "Epoch: 24/40... Step: 1/49... Loss: 0.01012565... Valid Loss: 0.01034750...\n",
      "Epoch: 24/40... Step: 11/49... Loss: 0.01081392... Valid Loss: 0.01034740...\n",
      "Epoch: 24/40... Step: 21/49... Loss: 0.01086568... Valid Loss: 0.01032100...\n",
      "Epoch: 24/40... Step: 31/49... Loss: 0.00966579... Valid Loss: 0.01026086...\n",
      "Epoch: 24/40... Step: 41/49... Loss: 0.01091438... Valid Loss: 0.01053150...\n",
      "Epoch: 25/40... Step: 1/49... Loss: 0.01065801... Valid Loss: 0.01045797...\n",
      "Epoch: 25/40... Step: 11/49... Loss: 0.01049361... Valid Loss: 0.01043445...\n",
      "Epoch: 25/40... Step: 21/49... Loss: 0.01128878... Valid Loss: 0.01092207...\n",
      "Epoch: 25/40... Step: 31/49... Loss: 0.01022640... Valid Loss: 0.01060462...\n",
      "Epoch: 25/40... Step: 41/49... Loss: 0.01028516... Valid Loss: 0.01030297...\n",
      "Epoch: 26/40... Step: 1/49... Loss: 0.01091999... Valid Loss: 0.01026897...\n",
      "Epoch: 26/40... Step: 11/49... Loss: 0.01078259... Valid Loss: 0.01032861...\n",
      "Epoch: 26/40... Step: 21/49... Loss: 0.01000397... Valid Loss: 0.01056197...\n",
      "Epoch: 26/40... Step: 31/49... Loss: 0.01144207... Valid Loss: 0.01093246...\n",
      "Epoch: 26/40... Step: 41/49... Loss: 0.01104084... Valid Loss: 0.01037472...\n",
      "Epoch: 27/40... Step: 1/49... Loss: 0.01062303... Valid Loss: 0.01056594...\n",
      "Epoch: 27/40... Step: 11/49... Loss: 0.00989817... Valid Loss: 0.01032883...\n",
      "Epoch: 27/40... Step: 21/49... Loss: 0.01034986... Valid Loss: 0.01038541...\n",
      "Epoch: 27/40... Step: 31/49... Loss: 0.01043514... Valid Loss: 0.01038105...\n",
      "Epoch: 27/40... Step: 41/49... Loss: 0.01065556... Valid Loss: 0.01042240...\n",
      "Epoch: 28/40... Step: 1/49... Loss: 0.00977056... Valid Loss: 0.01067481...\n",
      "Epoch: 28/40... Step: 11/49... Loss: 0.01073157... Valid Loss: 0.01100453...\n",
      "Epoch: 28/40... Step: 21/49... Loss: 0.01107089... Valid Loss: 0.01065652...\n",
      "Epoch: 28/40... Step: 31/49... Loss: 0.01117400... Valid Loss: 0.01057993...\n",
      "Epoch: 28/40... Step: 41/49... Loss: 0.01051280... Valid Loss: 0.01068481...\n",
      "Epoch: 29/40... Step: 1/49... Loss: 0.01013695... Valid Loss: 0.01040596...\n",
      "Epoch: 29/40... Step: 11/49... Loss: 0.01068743... Valid Loss: 0.01101629...\n",
      "Epoch: 29/40... Step: 21/49... Loss: 0.01068005... Valid Loss: 0.01080223...\n",
      "Epoch: 29/40... Step: 31/49... Loss: 0.01127080... Valid Loss: 0.01045466...\n",
      "Epoch: 29/40... Step: 41/49... Loss: 0.01107541... Valid Loss: 0.01042569...\n",
      "Epoch: 30/40... Step: 1/49... Loss: 0.01099083... Valid Loss: 0.01049116...\n",
      "Epoch: 30/40... Step: 11/49... Loss: 0.01095824... Valid Loss: 0.01092939...\n",
      "Epoch: 30/40... Step: 21/49... Loss: 0.01099370... Valid Loss: 0.01126286...\n",
      "Epoch: 30/40... Step: 31/49... Loss: 0.01057039... Valid Loss: 0.01050836...\n",
      "Epoch: 30/40... Step: 41/49... Loss: 0.01000014... Valid Loss: 0.01048011...\n",
      "Epoch: 31/40... Step: 1/49... Loss: 0.00988801... Valid Loss: 0.01025698...\n",
      "Epoch: 31/40... Step: 11/49... Loss: 0.01047323... Valid Loss: 0.01025640...\n",
      "Epoch: 31/40... Step: 21/49... Loss: 0.01117580... Valid Loss: 0.01033162...\n",
      "Epoch: 31/40... Step: 31/49... Loss: 0.00996887... Valid Loss: 0.01039984...\n",
      "Epoch: 31/40... Step: 41/49... Loss: 0.00994501... Valid Loss: 0.01054601...\n",
      "Epoch: 32/40... Step: 1/49... Loss: 0.00981110... Valid Loss: 0.01052277...\n",
      "Epoch: 32/40... Step: 11/49... Loss: 0.01066711... Valid Loss: 0.01036299...\n",
      "Epoch: 32/40... Step: 21/49... Loss: 0.01067759... Valid Loss: 0.01040153...\n",
      "Epoch: 32/40... Step: 31/49... Loss: 0.01078310... Valid Loss: 0.01047989...\n",
      "Epoch: 32/40... Step: 41/49... Loss: 0.01043602... Valid Loss: 0.01015085...\n",
      "Epoch: 33/40... Step: 1/49... Loss: 0.00436631... Valid Loss: 0.00460666...\n",
      "Valid loss decreased (0.010133-->0.004607). Saving model...\n",
      "Epoch: 33/40... Step: 11/49... Loss: 0.00343083... Valid Loss: 0.00361473...\n",
      "Valid loss decreased (0.004607-->0.003615). Saving model...\n",
      "Epoch: 33/40... Step: 21/49... Loss: 0.00397114... Valid Loss: 0.00359284...\n",
      "Valid loss decreased (0.003615-->0.003593). Saving model...\n",
      "Epoch: 33/40... Step: 31/49... Loss: 0.00353529... Valid Loss: 0.00365560...\n",
      "Epoch: 33/40... Step: 41/49... Loss: 0.00319640... Valid Loss: 0.00382075...\n",
      "Epoch: 34/40... Step: 1/49... Loss: 0.00349239... Valid Loss: 0.00356761...\n",
      "Valid loss decreased (0.003593-->0.003568). Saving model...\n",
      "Epoch: 34/40... Step: 11/49... Loss: 0.00397839... Valid Loss: 0.00350959...\n",
      "Valid loss decreased (0.003568-->0.003510). Saving model...\n",
      "Epoch: 34/40... Step: 21/49... Loss: 0.00342993... Valid Loss: 0.00356245...\n",
      "Epoch: 34/40... Step: 31/49... Loss: 0.00331566... Valid Loss: 0.00340660...\n",
      "Valid loss decreased (0.003510-->0.003407). Saving model...\n",
      "Epoch: 34/40... Step: 41/49... Loss: 0.00332758... Valid Loss: 0.00334710...\n",
      "Valid loss decreased (0.003407-->0.003347). Saving model...\n",
      "Epoch: 35/40... Step: 1/49... Loss: 0.00354552... Valid Loss: 0.00370555...\n",
      "Epoch: 35/40... Step: 11/49... Loss: 0.00350817... Valid Loss: 0.00342288...\n",
      "Epoch: 35/40... Step: 21/49... Loss: 0.00335223... Valid Loss: 0.00367111...\n",
      "Epoch: 35/40... Step: 31/49... Loss: 0.00426125... Valid Loss: 0.00430348...\n",
      "Epoch: 35/40... Step: 41/49... Loss: 0.00367440... Valid Loss: 0.00369814...\n",
      "Epoch: 36/40... Step: 1/49... Loss: 0.00299869... Valid Loss: 0.00320213...\n",
      "Valid loss decreased (0.003347-->0.003202). Saving model...\n",
      "Epoch: 36/40... Step: 11/49... Loss: 0.00326735... Valid Loss: 0.00332846...\n",
      "Epoch: 36/40... Step: 21/49... Loss: 0.00319514... Valid Loss: 0.00324657...\n",
      "Epoch: 36/40... Step: 31/49... Loss: 0.00290043... Valid Loss: 0.00316179...\n",
      "Valid loss decreased (0.003202-->0.003162). Saving model...\n",
      "Epoch: 36/40... Step: 41/49... Loss: 0.00384590... Valid Loss: 0.00348651...\n",
      "Epoch: 37/40... Step: 1/49... Loss: 0.00316233... Valid Loss: 0.00321316...\n",
      "Epoch: 37/40... Step: 11/49... Loss: 0.00378446... Valid Loss: 0.00358637...\n",
      "Epoch: 37/40... Step: 21/49... Loss: 0.00340359... Valid Loss: 0.00341650...\n",
      "Epoch: 37/40... Step: 31/49... Loss: 0.00306365... Valid Loss: 0.00366432...\n",
      "Epoch: 37/40... Step: 41/49... Loss: 0.00349081... Valid Loss: 0.00316589...\n",
      "Epoch: 38/40... Step: 1/49... Loss: 0.00403326... Valid Loss: 0.00358310...\n",
      "Epoch: 38/40... Step: 11/49... Loss: 0.00314139... Valid Loss: 0.00376114...\n",
      "Epoch: 38/40... Step: 21/49... Loss: 0.00347726... Valid Loss: 0.00346300...\n",
      "Epoch: 38/40... Step: 31/49... Loss: 0.00373676... Valid Loss: 0.00329387...\n",
      "Epoch: 38/40... Step: 41/49... Loss: 0.00352968... Valid Loss: 0.00349352...\n",
      "Epoch: 39/40... Step: 1/49... Loss: 0.00370965... Valid Loss: 0.00373694...\n",
      "Epoch: 39/40... Step: 11/49... Loss: 0.00291329... Valid Loss: 0.00344040...\n",
      "Epoch: 39/40... Step: 21/49... Loss: 0.00332957... Valid Loss: 0.00320292...\n",
      "Epoch: 39/40... Step: 31/49... Loss: 0.00323549... Valid Loss: 0.00328196...\n",
      "Epoch: 39/40... Step: 41/49... Loss: 0.00316295... Valid Loss: 0.00343022...\n",
      "Epoch: 40/40... Step: 1/49... Loss: 0.00341998... Valid Loss: 0.00328927...\n",
      "Epoch: 40/40... Step: 11/49... Loss: 0.00349250... Valid Loss: 0.00354164...\n",
      "Epoch: 40/40... Step: 21/49... Loss: 0.00390209... Valid Loss: 0.00337197...\n",
      "Epoch: 40/40... Step: 31/49... Loss: 0.00357815... Valid Loss: 0.00346516...\n",
      "Epoch: 40/40... Step: 41/49... Loss: 0.00316147... Valid Loss: 0.00377869...\n"
     ]
    }
   ],
   "source": [
    "(MAPE_list, MAE_list, RMSE_list, load_pred, load_true, model) = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1635327898631,
     "user": {
      "displayName": "Mark Dong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04537685704836554558"
     },
     "user_tz": -480
    },
    "id": "JRjWNTa5ArIK",
    "outputId": "66b3de2d-7eae-4e7f-d90b-b983ea45e167"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.06428769584947097], [805.3625697544215], [1047.079509281207])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE_list, MAE_list, RMSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1635327930309,
     "user": {
      "displayName": "Mark Dong",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "04537685704836554558"
     },
     "user_tz": -480
    },
    "id": "DoeoVbj-_32I",
    "outputId": "d7db78d1-bdb8-4b1c-994c-6dcff7fc31ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8372644990>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(load_pred[0:240], 'r')\n",
    "plt.plot(load_true[0:240], 'g')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FNN-1027.ipynb",
   "provenance": [
    {
     "file_id": "1JnY81SzKkuYnz0eoAeX6P74aYK2GBTfi",
     "timestamp": 1635316910538
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "241px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
